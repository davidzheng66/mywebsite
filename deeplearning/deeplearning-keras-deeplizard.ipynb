{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzi1jRiStsEhnDw89NjSSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidzheng66/python3/blob/master/deeplearning/deeplearning-keras-deeplizard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5mcjXt94xi"
      },
      "source": [
        "#[Prerequisite: Machine Learning and Deep Learning Fundamental - deeplizard](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWU2iwq0vS0y"
      },
      "source": [
        "##[1. Deep Learning Overview & Machine Learning Introduction](https://www.youtube.com/watch?v=gZmobeGL0Yg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su13EwxuvrWd"
      },
      "source": [
        "##[2. Deep Learning](https://www.youtube.com/watch?v=OT1jslLoCyA&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Riqx8N0pvzLw"
      },
      "source": [
        "##[3. Artificial Neural Network (ANN)](https://www.youtube.com/watch?v=hfK_dvC-avg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEj1AiG2v-K3"
      },
      "source": [
        "##[4. Layers in a Neural Network](https://www.youtube.com/watch?v=FK77zZxaBoI&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=4)\r\n",
        "###Layers in an ANN\r\n",
        "Artificial neural network is typically organized in layers. Different types of layers include:\r\n",
        "* Dense (or fully connected) Layers\r\n",
        "* Convolutional layers\r\n",
        "* Pooling Layers\r\n",
        "* Recurrent Layers\r\n",
        "* Normalization Layers\r\n",
        "* Many others\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9XefjIhwJQu"
      },
      "source": [
        "##[5. Activation Functions in a Neural Network](https://www.youtube.com/watch?v=m0pIlLfpXWE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=5)\r\n",
        "###Activation Functions\r\n",
        "In an artificial neural network, the activation function of a neuron defines the output of that neuro given a set of inputs.\r\n",
        "* Biologically inspired by activity in our brains, where different neurons fire, or are activated, by different stimuli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZrEddwgrYh"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "\r\n",
        "#Way 1 to create a model\r\n",
        "model = Sequential([\r\n",
        "    Dense(5, input_shape=(3,), activation='relu')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClYbS3INhE7z"
      },
      "source": [
        "#Way 2 to create a model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(5, input_shape=(3,)))\r\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvpdGUJkhfL"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "\r\n",
        "#Way 1 to create a model\r\n",
        "model = Sequential([\r\n",
        "    Dense(5, input_shape=(3,), activation='relu'),\r\n",
        "    Dense(2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqFslPPxk2pJ"
      },
      "source": [
        "import numpy as np\r\n",
        "# from scipy import ndimage\r\n",
        "from scipy import misc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# img = np.expand_dims(ndimage.imread('NN.PNG'), 0)\r\n",
        "img = np.expand_dims(misc.imread('NN.PNG'), 0)\r\n",
        "plt.imshow(img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-8_oiL7oXsQ"
      },
      "source": [
        "##[6. Training a Neural Network](https://www.youtube.com/watch?v=sZAlS3_dnk0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ID4nh1MoqIB"
      },
      "source": [
        "###Training\r\n",
        "Solving an optimization proble\r\n",
        "* Optimizing weights\r\n",
        " * with Stochastic Gradient Descent (SGD)\r\n",
        "* Objective: Minimize the loss function\r\n",
        "\r\n",
        "###Learning\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06JwRVlJw6gs"
      },
      "source": [
        "##[7. How a Neural Network Learns](https://www.youtube.com/watch?v=_N5kpSMDf4o&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lomcNRe0xCNC"
      },
      "source": [
        "##[8. Loss in a Neural Network](https://www.youtube.com/watch?v=Skc8nqJirJg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSMjjyC-xKp0"
      },
      "source": [
        "##[9. Learning Rate in a Neural Network](https://www.youtube.com/watch?v=jWT-AX9677k&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NItVj2dExT_S"
      },
      "source": [
        "##[10. Train, Test & Validation Sets](https://www.youtube.com/watch?v=Zi-0rlM4RDs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os2vLwDDxery"
      },
      "source": [
        "##[11. Predicting with a Neural Network](https://www.youtube.com/watch?v=Z0KVRdE_a7Q&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zu0NQUkxneE"
      },
      "source": [
        "##[12. Overfitting in a Neural Network](https://www.youtube.com/watch?v=DEMmkFC6IGM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86EHAHKmxveB"
      },
      "source": [
        "##[13. Underfitting in a Neural Network](https://www.youtube.com/watch?v=0h8lAm5Ki5g&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrfD7QGx5Dh"
      },
      "source": [
        "##[14. Supervised Learning](https://www.youtube.com/watch?v=Quh6x4kG6VY&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL-mW3ExyDCS"
      },
      "source": [
        "##[15. Unsupervised Learning](https://www.youtube.com/watch?v=lEfrr0Yr684&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4FOWKtyKaz"
      },
      "source": [
        "##[16. Semi-supervised Learning](https://www.youtube.com/watch?v=b-yhKUINb7o&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC_rtFEnyRPS"
      },
      "source": [
        "##[17. Data Augmentation](https://www.youtube.com/watch?v=rfM4DaLTkMs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybGFKyXYyX4a"
      },
      "source": [
        "##[18. One-hot Encoding](https://www.youtube.com/watch?v=v_4KWmkwmsU&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIBs1Mihyfxp"
      },
      "source": [
        "##[19. Convolutional Neural Networks](https://www.youtube.com/watch?v=YRhxdVk_sIs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=19)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3JxHihWyqIK"
      },
      "source": [
        "##[20. Visualizing Convolutional Filters from a CNN](https://www.youtube.com/watch?v=cNBBNAxC8l4&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx2am-khy4ai"
      },
      "source": [
        "##[21. Zero Padding in Convolutional Neural Networks](https://www.youtube.com/watch?v=qSTv_m-KFk0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArRuAPNrzD8q"
      },
      "source": [
        "##[22. Max Pooling in Convolutional Neural Networks](https://www.youtube.com/watch?v=ZjM_XQa5s6s&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVWiU3W_zQdO"
      },
      "source": [
        "##[23. Backpropagation | Part 1 - The Intuition](https://www.youtube.com/watch?v=XE3krf3CQls&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I12zwfgSzeV7"
      },
      "source": [
        "##[24. Backpropagation | Part 2 - The Mathematical Notation](https://www.youtube.com/watch?v=2mSysRx-1c0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbuzZSzuztDh"
      },
      "source": [
        "##[25. Backpropagation | Part 3 - Mathematical Observations](https://www.youtube.com/watch?v=G5b4jRBKNxw&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye5UXLt3z9dS"
      },
      "source": [
        "##[26. Backpropagation | Part 4 - Calculating the Gradient](https://www.youtube.com/watch?v=Zr5viAZGndE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=26)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tomxx2w20IRS"
      },
      "source": [
        "##[27. Backpropagation | Part 5 - What Puts the \"back\" in Backprop?](https://www.youtube.com/watch?v=xClK__CqZnQ&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=27)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2x1lbfxR2ZR"
      },
      "source": [
        "##[28. Vanishing & Exploding Gradient | A Problem Resulting from Backprogagation](https://www.youtube.com/watch?v=qO_NLVjD6zE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=28)\r\n",
        "- Gradient: referrring to the gradient of the loss function with respect to the weights in the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0IzlBUBUi7k"
      },
      "source": [
        "##[29. Weight Initialization | A Way to Reduce the Vanishing Gradient Problem](https://www.youtube.com/watch?v=8krd5qKVw-Q&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA1f8ZVpXeQH"
      },
      "source": [
        "##[30. Bias in an Artificial Neural Network | How Bias Impacts Training](https://www.youtube.com/watch?v=HetFihsXSys&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpgRyhDjgxcI"
      },
      "source": [
        "##[31. Learnable Parameters in an Artificial Neural Network](https://www.youtube.com/watch?v=pg3hJpSopHQ&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=31)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd7diOMEj5wa"
      },
      "source": [
        "##[32. Learnable Parameters in a Convolutional Neural Network (CNN)](https://www.youtube.com/watch?v=gmBfb6LNnZs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MePjTZIMXp_B"
      },
      "source": [
        "##[33. Regularization in a Neural Network](https://www.youtube.com/watch?v=iuJgyiS7BKM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP06JifmqTB-"
      },
      "source": [
        "##[34. Batch Size in a Neural Network](https://www.youtube.com/watch?v=U4WB9p6ODjM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlGcmepPrUZE"
      },
      "source": [
        "##[35. Fine-tuning a Neural Network](https://www.youtube.com/watch?v=5T-iXNNiwIs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3zR-SstIab"
      },
      "source": [
        "##[36. Batch Normalization (\"batch norm\")](https://www.youtube.com/watch?v=dXB-KQYkzNU&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=36)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcXKWvR4BX6z"
      },
      "source": [
        "#[Keras with TensorFlow Course - Python Deep Learning and Neural Networks for Beginners Tutorial](https://www.youtube.com/watch?v=qFJeN9V1ZsI&t=94s)\r\n",
        "- ⌨️ (00:00:00) Welcome to this course\r\n",
        "- ⌨️ (00:00:16) Keras Course Introduction\r\n",
        "- ⌨️ (00:00:50) Course Prerequisites\r\n",
        "- ⌨️ (00:01:33) DEEPLIZARD Deep Learning Path\r\n",
        "- ⌨️ (00:01:45) Course Resources\r\n",
        "- ⌨️ (00:02:30) About Keras\r\n",
        "- ⌨️ (00:06:41) Keras with TensorFlow - Data Processing for Neural Network Training\r\n",
        "- ⌨️ (00:18:39) Create an Artificial Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:24:36) Train an Artificial Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:30:07) Build a Validation Set With TensorFlow's Keras API\r\n",
        "- ⌨️ (00:39:28) Neural Network Predictions with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:47:48) Create a Confusion Matrix for Neural Network Predictions\r\n",
        "- ⌨️ (00:52:29) Save and Load a Model with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:01:25) Image Preparation for CNNs with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:19:22) Build and Train a CNN with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:28:42) CNN Predictions with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:37:05) Build a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:48:19) Train a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:52:39) Predict with a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:57:50) MobileNet Image Classification with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:11:18) Process Images for Fine-Tuned MobileNet with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:24:24) Fine-Tuning MobileNet on Custom Data Set with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:38:59) Data Augmentation with TensorFlow' Keras API\r\n",
        "- ⌨️ (02:47:24) Collective Intelligence and the DEEPLIZARD HIVEMIND\r\n",
        "\r\n",
        "##[Keras](https://keras.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkrMXKB2FM9O"
      },
      "source": [
        "##Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqx_3BJuFMH9"
      },
      "source": [
        "import numpy as np\r\n",
        "from random import randint\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBPczNLGCxl"
      },
      "source": [
        "### Example data:\r\n",
        "- An experiemental drug was tested on individuals from ages 13 to 100 in a clinical trial.\r\n",
        "- The trial has 2100 participants. Half were under 65 years old, half were 65 years older.\r\n",
        "- Around 95% of patients 65 or older experienced side effects.\r\n",
        "- Around 95% of patients under 65 experienced no side effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0MtYZNkFzky"
      },
      "source": [
        "train_labels = []\r\n",
        "train_samples = []\r\n",
        "\r\n",
        "for i in range(50):\r\n",
        "  # The ~5% of younger individuals who did experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  train_samples.append(random_younger)\r\n",
        "  train_labels.append(1)\r\n",
        "\r\n",
        "  # The ~5% of older individuals who did not experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  train_samples.append(random_older)\r\n",
        "  train_labels.append(0)\r\n",
        "\r\n",
        "for i in range(1000):\r\n",
        "  # The ~95% of younger individuals who did not experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  train_samples.append(random_younger)\r\n",
        "  train_labels.append(0)\r\n",
        "\r\n",
        "  # The ~95% of older individuals who did experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  train_samples.append(random_older)\r\n",
        "  train_labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq8VcMQhKA3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07633969-4660-4690-a1d9-1ff152f3d7e1"
      },
      "source": [
        "train_labels = np.array(train_labels)\r\n",
        "train_samples = np.array(train_samples)\r\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)\r\n",
        "\r\n",
        "print(train_labels)\r\n",
        "print(train_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 1 0]\n",
            "[67 30 79 ... 69 95 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO2MVDLb8RKE",
        "outputId": "4c8cad16-a631-451b-f3fb-ac81dd41a14d"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\r\n",
        "print(scaler)\r\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))\r\n",
        "print(scaled_train_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "[[0.62068966]\n",
            " [0.1954023 ]\n",
            " [0.75862069]\n",
            " ...\n",
            " [0.64367816]\n",
            " [0.94252874]\n",
            " [0.1954023 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V05dNMgk9OfF"
      },
      "source": [
        "##Create an Artificial Neural Network with TensorFlow's Keras API \r\n",
        "###Simple tf.keras Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcds_84B9WY8"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Activation, Dense\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "7_TG1fnB93LG",
        "outputId": "8cef5a1a-1930-480d-ea1a-2188ba94a8cb"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "print('Num GPUs Available: ', len(physical_devices))\r\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b42eb6479b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Num GPUs Available: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAy70bCb-OCc"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\r\n",
        "    Dense(units=32, activation='relu'),\r\n",
        "    Dense(units=2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-lqVj8E86AN",
        "outputId": "c142ecbe-8cff-41c6-853c-f5023e6eab8f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrW7MSDP_2DT"
      },
      "source": [
        "## Train an Artificial Neural Network with TensorFlow's Keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWDpFKyl-45J",
        "outputId": "c7bb1300-d5a7-4fb6-a358-09a6760b816d"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 0s - loss: 0.2330 - accuracy: 0.9524\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.2330 - accuracy: 0.9505\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.2328 - accuracy: 0.9514\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.2328 - accuracy: 0.9524\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.2327 - accuracy: 0.9524\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.2327 - accuracy: 0.9524\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.2325 - accuracy: 0.9524\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.2324 - accuracy: 0.9524\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.2323 - accuracy: 0.9524\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.2322 - accuracy: 0.9490\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.2321 - accuracy: 0.9524\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.2320 - accuracy: 0.9524\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.2320 - accuracy: 0.9524\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.2318 - accuracy: 0.9524\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.2319 - accuracy: 0.9524\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.2317 - accuracy: 0.9524\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2317 - accuracy: 0.9524\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2315 - accuracy: 0.9524\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2312 - accuracy: 0.9524\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2311 - accuracy: 0.9524\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2311 - accuracy: 0.9524\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2310 - accuracy: 0.9495\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2309 - accuracy: 0.9524\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2307 - accuracy: 0.9495\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2308 - accuracy: 0.9524\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2306 - accuracy: 0.9524\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2306 - accuracy: 0.9524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd33bb5c208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBj3KDGoB_0w"
      },
      "source": [
        "##Build a Validation Set With TensorFlow's Keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rli-mnu0CDpd",
        "outputId": "325bb287-c3c8-499d-d4d0-9d3a1ddbed26"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 1s - loss: 0.7230 - accuracy: 0.4968 - val_loss: 0.7029 - val_accuracy: 0.5238\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.6852 - accuracy: 0.5937 - val_loss: 0.6667 - val_accuracy: 0.6857\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.6494 - accuracy: 0.7148 - val_loss: 0.6307 - val_accuracy: 0.7333\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.6192 - accuracy: 0.7275 - val_loss: 0.5994 - val_accuracy: 0.7714\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.5893 - accuracy: 0.7545 - val_loss: 0.5663 - val_accuracy: 0.8048\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.5595 - accuracy: 0.7735 - val_loss: 0.5327 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.5316 - accuracy: 0.8079 - val_loss: 0.5027 - val_accuracy: 0.8667\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.5046 - accuracy: 0.8302 - val_loss: 0.4722 - val_accuracy: 0.8810\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.4785 - accuracy: 0.8460 - val_loss: 0.4427 - val_accuracy: 0.9000\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.4538 - accuracy: 0.8561 - val_loss: 0.4148 - val_accuracy: 0.9000\n",
            "Epoch 11/30\n",
            "189/189 - 0s - loss: 0.4308 - accuracy: 0.8704 - val_loss: 0.3894 - val_accuracy: 0.9048\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.4099 - accuracy: 0.8778 - val_loss: 0.3661 - val_accuracy: 0.9190\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.3911 - accuracy: 0.8868 - val_loss: 0.3447 - val_accuracy: 0.9238\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.3744 - accuracy: 0.8974 - val_loss: 0.3267 - val_accuracy: 0.9238\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.3598 - accuracy: 0.9005 - val_loss: 0.3102 - val_accuracy: 0.9238\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.3472 - accuracy: 0.9063 - val_loss: 0.2963 - val_accuracy: 0.9238\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.3365 - accuracy: 0.9090 - val_loss: 0.2844 - val_accuracy: 0.9381\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.3273 - accuracy: 0.9122 - val_loss: 0.2743 - val_accuracy: 0.9381\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.3196 - accuracy: 0.9116 - val_loss: 0.2653 - val_accuracy: 0.9381\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.3128 - accuracy: 0.9212 - val_loss: 0.2577 - val_accuracy: 0.9381\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.3072 - accuracy: 0.9206 - val_loss: 0.2510 - val_accuracy: 0.9429\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.3020 - accuracy: 0.9212 - val_loss: 0.2452 - val_accuracy: 0.9429\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2979 - accuracy: 0.9270 - val_loss: 0.2403 - val_accuracy: 0.9476\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2941 - accuracy: 0.9254 - val_loss: 0.2360 - val_accuracy: 0.9476\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2910 - accuracy: 0.9307 - val_loss: 0.2324 - val_accuracy: 0.9429\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2885 - accuracy: 0.9270 - val_loss: 0.2289 - val_accuracy: 0.9476\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2858 - accuracy: 0.9323 - val_loss: 0.2261 - val_accuracy: 0.9476\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2837 - accuracy: 0.9323 - val_loss: 0.2233 - val_accuracy: 0.9476\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2817 - accuracy: 0.9323 - val_loss: 0.2211 - val_accuracy: 0.9476\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2801 - accuracy: 0.9328 - val_loss: 0.2189 - val_accuracy: 0.9476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee5062a208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9I43_ESGcdP"
      },
      "source": [
        "##Neural Network Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZwJ8g27GhOY"
      },
      "source": [
        "test_labels = []\r\n",
        "test_samples = []\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  # The ~5% of younger individuals who did experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  test_samples.append(random_younger)\r\n",
        "  test_labels.append(1)\r\n",
        "\r\n",
        "  # The ~5% of older individuals who did not experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  test_samples.append(random_older)\r\n",
        "  test_labels.append(0)\r\n",
        "\r\n",
        "for i in range(200):\r\n",
        "  # The ~95% of younger individuals who did not experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  test_samples.append(random_younger)\r\n",
        "  test_labels.append(0)\r\n",
        "\r\n",
        "  # The ~95% of older individuals who did experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  test_samples.append(random_older)\r\n",
        "  test_labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU1SHdeaHiAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7120b995-608b-4e99-d717-a970a15c44df"
      },
      "source": [
        "test_labels = np.array(test_labels)\r\n",
        "test_samples = np.array(test_samples)\r\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)\r\n",
        "\r\n",
        "print(test_labels)\r\n",
        "print(test_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1\n",
            " 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 0 1 1 1 1 0 0]\n",
            "[ 56  69  68  89  91  31  96  39  43  26  30  24  31  70  80  38  77  33\n",
            "  26  86  22  39  51  52  25  73  70  84 100  70  93  91  52  38  98  89\n",
            "  88  69  59  89  47  66  62  82  95  54  59  97  96  84  65  25  30  68\n",
            "  77  97  37  88  93  27  17  95  37  32  92  93  94  96  80  68  30  71\n",
            "  35  68  67  65  70  58  28  88  36  77  73  37  44  98  88  43  18  77\n",
            "  73  58  63  86  90  99  59  83  32  59  46  44  94  70  74  72  56  75\n",
            "  25  99  89  75  81  47  72  90  13  71  48  44  32  34  98  72  72  15\n",
            "  66  91  47  93  95  50  73  69  78  56  36  62  62  26  98  75  80  68\n",
            "  36  68  84  42  31  50  88  68  51  22  42  63  86  88  90  21  94  55\n",
            "  42  51  66  35  98  26  59  22  75  92  48  38  95  68  68  24  39  49\n",
            "  94  74  66  97  86  96  37  72  17  92  75  42  65  40  42  26  45  83\n",
            "  30  90  89  91  44  90  27  66  86  43  77  40  65  35  47  93  35  13\n",
            "  57  92  17  96  66  62  88  13  40  52  46  57  32  68  41  37  78  30\n",
            "  89  94  88  45  67  31  27  41  67  97  16  50  73  23  69  34  51  31\n",
            "  68  13  72  76  87  58  75  29  58  80  69  97  72  57  34  39  84  37\n",
            "  79  42  28  66  86  27  78  38  33  81  29  89  43  59  42  41  19  49\n",
            "  16  62  35  53  71  99  14  23  95  90  83  40  76  61  85  75  68  28\n",
            "  44  15  80  67  68  31  56  53  88  14  36  69  96  16  30  26  49  91\n",
            "  66  52  52  87  49  59  72  96  57  78  50  26  50  83  60  62  56  58\n",
            "  37  33  89  31  91  44  33  67  47  53  19  78  80  42  88  99  85  23\n",
            "  18  91  70  51  56  85  55  69  72  78  17  87  88  70  45  83  19  94\n",
            "  80  68  78  58  72  57  69  88  78  19  47  26  80  32  54  79  66  35\n",
            " 100  41  51  44  58  79  21  99  98  18  46  68  32  73  82  59  83  30\n",
            "  65  88  83  96  33  34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vGN3pjYHz5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2a72f8-9a3a-4f56-f8a2-8735962e970c"
      },
      "source": [
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))\r\n",
        "print(scaled_test_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.49425287]\n",
            " [0.64367816]\n",
            " [0.63218391]\n",
            " [0.87356322]\n",
            " [0.89655172]\n",
            " [0.20689655]\n",
            " [0.95402299]\n",
            " [0.29885057]\n",
            " [0.34482759]\n",
            " [0.14942529]\n",
            " [0.1954023 ]\n",
            " [0.12643678]\n",
            " [0.20689655]\n",
            " [0.65517241]\n",
            " [0.77011494]\n",
            " [0.28735632]\n",
            " [0.73563218]\n",
            " [0.22988506]\n",
            " [0.14942529]\n",
            " [0.83908046]\n",
            " [0.10344828]\n",
            " [0.29885057]\n",
            " [0.43678161]\n",
            " [0.44827586]\n",
            " [0.13793103]\n",
            " [0.68965517]\n",
            " [0.65517241]\n",
            " [0.81609195]\n",
            " [1.        ]\n",
            " [0.65517241]\n",
            " [0.91954023]\n",
            " [0.89655172]\n",
            " [0.44827586]\n",
            " [0.28735632]\n",
            " [0.97701149]\n",
            " [0.87356322]\n",
            " [0.86206897]\n",
            " [0.64367816]\n",
            " [0.52873563]\n",
            " [0.87356322]\n",
            " [0.3908046 ]\n",
            " [0.6091954 ]\n",
            " [0.56321839]\n",
            " [0.79310345]\n",
            " [0.94252874]\n",
            " [0.47126437]\n",
            " [0.52873563]\n",
            " [0.96551724]\n",
            " [0.95402299]\n",
            " [0.81609195]\n",
            " [0.59770115]\n",
            " [0.13793103]\n",
            " [0.1954023 ]\n",
            " [0.63218391]\n",
            " [0.73563218]\n",
            " [0.96551724]\n",
            " [0.27586207]\n",
            " [0.86206897]\n",
            " [0.91954023]\n",
            " [0.16091954]\n",
            " [0.04597701]\n",
            " [0.94252874]\n",
            " [0.27586207]\n",
            " [0.2183908 ]\n",
            " [0.90804598]\n",
            " [0.91954023]\n",
            " [0.93103448]\n",
            " [0.95402299]\n",
            " [0.77011494]\n",
            " [0.63218391]\n",
            " [0.1954023 ]\n",
            " [0.66666667]\n",
            " [0.25287356]\n",
            " [0.63218391]\n",
            " [0.62068966]\n",
            " [0.59770115]\n",
            " [0.65517241]\n",
            " [0.51724138]\n",
            " [0.17241379]\n",
            " [0.86206897]\n",
            " [0.26436782]\n",
            " [0.73563218]\n",
            " [0.68965517]\n",
            " [0.27586207]\n",
            " [0.35632184]\n",
            " [0.97701149]\n",
            " [0.86206897]\n",
            " [0.34482759]\n",
            " [0.05747126]\n",
            " [0.73563218]\n",
            " [0.68965517]\n",
            " [0.51724138]\n",
            " [0.57471264]\n",
            " [0.83908046]\n",
            " [0.88505747]\n",
            " [0.98850575]\n",
            " [0.52873563]\n",
            " [0.8045977 ]\n",
            " [0.2183908 ]\n",
            " [0.52873563]\n",
            " [0.37931034]\n",
            " [0.35632184]\n",
            " [0.93103448]\n",
            " [0.65517241]\n",
            " [0.70114943]\n",
            " [0.67816092]\n",
            " [0.49425287]\n",
            " [0.71264368]\n",
            " [0.13793103]\n",
            " [0.98850575]\n",
            " [0.87356322]\n",
            " [0.71264368]\n",
            " [0.7816092 ]\n",
            " [0.3908046 ]\n",
            " [0.67816092]\n",
            " [0.88505747]\n",
            " [0.        ]\n",
            " [0.66666667]\n",
            " [0.40229885]\n",
            " [0.35632184]\n",
            " [0.2183908 ]\n",
            " [0.24137931]\n",
            " [0.97701149]\n",
            " [0.67816092]\n",
            " [0.67816092]\n",
            " [0.02298851]\n",
            " [0.6091954 ]\n",
            " [0.89655172]\n",
            " [0.3908046 ]\n",
            " [0.91954023]\n",
            " [0.94252874]\n",
            " [0.42528736]\n",
            " [0.68965517]\n",
            " [0.64367816]\n",
            " [0.74712644]\n",
            " [0.49425287]\n",
            " [0.26436782]\n",
            " [0.56321839]\n",
            " [0.56321839]\n",
            " [0.14942529]\n",
            " [0.97701149]\n",
            " [0.71264368]\n",
            " [0.77011494]\n",
            " [0.63218391]\n",
            " [0.26436782]\n",
            " [0.63218391]\n",
            " [0.81609195]\n",
            " [0.33333333]\n",
            " [0.20689655]\n",
            " [0.42528736]\n",
            " [0.86206897]\n",
            " [0.63218391]\n",
            " [0.43678161]\n",
            " [0.10344828]\n",
            " [0.33333333]\n",
            " [0.57471264]\n",
            " [0.83908046]\n",
            " [0.86206897]\n",
            " [0.88505747]\n",
            " [0.09195402]\n",
            " [0.93103448]\n",
            " [0.48275862]\n",
            " [0.33333333]\n",
            " [0.43678161]\n",
            " [0.6091954 ]\n",
            " [0.25287356]\n",
            " [0.97701149]\n",
            " [0.14942529]\n",
            " [0.52873563]\n",
            " [0.10344828]\n",
            " [0.71264368]\n",
            " [0.90804598]\n",
            " [0.40229885]\n",
            " [0.28735632]\n",
            " [0.94252874]\n",
            " [0.63218391]\n",
            " [0.63218391]\n",
            " [0.12643678]\n",
            " [0.29885057]\n",
            " [0.4137931 ]\n",
            " [0.93103448]\n",
            " [0.70114943]\n",
            " [0.6091954 ]\n",
            " [0.96551724]\n",
            " [0.83908046]\n",
            " [0.95402299]\n",
            " [0.27586207]\n",
            " [0.67816092]\n",
            " [0.04597701]\n",
            " [0.90804598]\n",
            " [0.71264368]\n",
            " [0.33333333]\n",
            " [0.59770115]\n",
            " [0.31034483]\n",
            " [0.33333333]\n",
            " [0.14942529]\n",
            " [0.36781609]\n",
            " [0.8045977 ]\n",
            " [0.1954023 ]\n",
            " [0.88505747]\n",
            " [0.87356322]\n",
            " [0.89655172]\n",
            " [0.35632184]\n",
            " [0.88505747]\n",
            " [0.16091954]\n",
            " [0.6091954 ]\n",
            " [0.83908046]\n",
            " [0.34482759]\n",
            " [0.73563218]\n",
            " [0.31034483]\n",
            " [0.59770115]\n",
            " [0.25287356]\n",
            " [0.3908046 ]\n",
            " [0.91954023]\n",
            " [0.25287356]\n",
            " [0.        ]\n",
            " [0.50574713]\n",
            " [0.90804598]\n",
            " [0.04597701]\n",
            " [0.95402299]\n",
            " [0.6091954 ]\n",
            " [0.56321839]\n",
            " [0.86206897]\n",
            " [0.        ]\n",
            " [0.31034483]\n",
            " [0.44827586]\n",
            " [0.37931034]\n",
            " [0.50574713]\n",
            " [0.2183908 ]\n",
            " [0.63218391]\n",
            " [0.32183908]\n",
            " [0.27586207]\n",
            " [0.74712644]\n",
            " [0.1954023 ]\n",
            " [0.87356322]\n",
            " [0.93103448]\n",
            " [0.86206897]\n",
            " [0.36781609]\n",
            " [0.62068966]\n",
            " [0.20689655]\n",
            " [0.16091954]\n",
            " [0.32183908]\n",
            " [0.62068966]\n",
            " [0.96551724]\n",
            " [0.03448276]\n",
            " [0.42528736]\n",
            " [0.68965517]\n",
            " [0.11494253]\n",
            " [0.64367816]\n",
            " [0.24137931]\n",
            " [0.43678161]\n",
            " [0.20689655]\n",
            " [0.63218391]\n",
            " [0.        ]\n",
            " [0.67816092]\n",
            " [0.72413793]\n",
            " [0.85057471]\n",
            " [0.51724138]\n",
            " [0.71264368]\n",
            " [0.18390805]\n",
            " [0.51724138]\n",
            " [0.77011494]\n",
            " [0.64367816]\n",
            " [0.96551724]\n",
            " [0.67816092]\n",
            " [0.50574713]\n",
            " [0.24137931]\n",
            " [0.29885057]\n",
            " [0.81609195]\n",
            " [0.27586207]\n",
            " [0.75862069]\n",
            " [0.33333333]\n",
            " [0.17241379]\n",
            " [0.6091954 ]\n",
            " [0.83908046]\n",
            " [0.16091954]\n",
            " [0.74712644]\n",
            " [0.28735632]\n",
            " [0.22988506]\n",
            " [0.7816092 ]\n",
            " [0.18390805]\n",
            " [0.87356322]\n",
            " [0.34482759]\n",
            " [0.52873563]\n",
            " [0.33333333]\n",
            " [0.32183908]\n",
            " [0.06896552]\n",
            " [0.4137931 ]\n",
            " [0.03448276]\n",
            " [0.56321839]\n",
            " [0.25287356]\n",
            " [0.45977011]\n",
            " [0.66666667]\n",
            " [0.98850575]\n",
            " [0.01149425]\n",
            " [0.11494253]\n",
            " [0.94252874]\n",
            " [0.88505747]\n",
            " [0.8045977 ]\n",
            " [0.31034483]\n",
            " [0.72413793]\n",
            " [0.55172414]\n",
            " [0.82758621]\n",
            " [0.71264368]\n",
            " [0.63218391]\n",
            " [0.17241379]\n",
            " [0.35632184]\n",
            " [0.02298851]\n",
            " [0.77011494]\n",
            " [0.62068966]\n",
            " [0.63218391]\n",
            " [0.20689655]\n",
            " [0.49425287]\n",
            " [0.45977011]\n",
            " [0.86206897]\n",
            " [0.01149425]\n",
            " [0.26436782]\n",
            " [0.64367816]\n",
            " [0.95402299]\n",
            " [0.03448276]\n",
            " [0.1954023 ]\n",
            " [0.14942529]\n",
            " [0.4137931 ]\n",
            " [0.89655172]\n",
            " [0.6091954 ]\n",
            " [0.44827586]\n",
            " [0.44827586]\n",
            " [0.85057471]\n",
            " [0.4137931 ]\n",
            " [0.52873563]\n",
            " [0.67816092]\n",
            " [0.95402299]\n",
            " [0.50574713]\n",
            " [0.74712644]\n",
            " [0.42528736]\n",
            " [0.14942529]\n",
            " [0.42528736]\n",
            " [0.8045977 ]\n",
            " [0.54022989]\n",
            " [0.56321839]\n",
            " [0.49425287]\n",
            " [0.51724138]\n",
            " [0.27586207]\n",
            " [0.22988506]\n",
            " [0.87356322]\n",
            " [0.20689655]\n",
            " [0.89655172]\n",
            " [0.35632184]\n",
            " [0.22988506]\n",
            " [0.62068966]\n",
            " [0.3908046 ]\n",
            " [0.45977011]\n",
            " [0.06896552]\n",
            " [0.74712644]\n",
            " [0.77011494]\n",
            " [0.33333333]\n",
            " [0.86206897]\n",
            " [0.98850575]\n",
            " [0.82758621]\n",
            " [0.11494253]\n",
            " [0.05747126]\n",
            " [0.89655172]\n",
            " [0.65517241]\n",
            " [0.43678161]\n",
            " [0.49425287]\n",
            " [0.82758621]\n",
            " [0.48275862]\n",
            " [0.64367816]\n",
            " [0.67816092]\n",
            " [0.74712644]\n",
            " [0.04597701]\n",
            " [0.85057471]\n",
            " [0.86206897]\n",
            " [0.65517241]\n",
            " [0.36781609]\n",
            " [0.8045977 ]\n",
            " [0.06896552]\n",
            " [0.93103448]\n",
            " [0.77011494]\n",
            " [0.63218391]\n",
            " [0.74712644]\n",
            " [0.51724138]\n",
            " [0.67816092]\n",
            " [0.50574713]\n",
            " [0.64367816]\n",
            " [0.86206897]\n",
            " [0.74712644]\n",
            " [0.06896552]\n",
            " [0.3908046 ]\n",
            " [0.14942529]\n",
            " [0.77011494]\n",
            " [0.2183908 ]\n",
            " [0.47126437]\n",
            " [0.75862069]\n",
            " [0.6091954 ]\n",
            " [0.25287356]\n",
            " [1.        ]\n",
            " [0.32183908]\n",
            " [0.43678161]\n",
            " [0.35632184]\n",
            " [0.51724138]\n",
            " [0.75862069]\n",
            " [0.09195402]\n",
            " [0.98850575]\n",
            " [0.97701149]\n",
            " [0.05747126]\n",
            " [0.37931034]\n",
            " [0.63218391]\n",
            " [0.2183908 ]\n",
            " [0.68965517]\n",
            " [0.79310345]\n",
            " [0.52873563]\n",
            " [0.8045977 ]\n",
            " [0.1954023 ]\n",
            " [0.59770115]\n",
            " [0.86206897]\n",
            " [0.8045977 ]\n",
            " [0.95402299]\n",
            " [0.22988506]\n",
            " [0.24137931]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYLwiLfjIRVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f596ef-9f60-4b2c-eada-d79fb0856e42"
      },
      "source": [
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)\r\n",
        "print(predictions.shape)\r\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 2)\n",
            "[[0.6971599  0.30284008]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.04931042 0.95068955]\n",
            " [0.04366032 0.95633966]\n",
            " [0.9554998  0.04450024]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.9352111  0.06478888]\n",
            " [0.90959454 0.09040547]\n",
            " [0.9549728  0.04502725]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.95468444 0.0453156 ]\n",
            " [0.9554998  0.04450024]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.10863506 0.89136493]\n",
            " [0.9401946  0.05980542]\n",
            " [0.1496386  0.8503614 ]\n",
            " [0.95370024 0.04629977]\n",
            " [0.9549728  0.04502725]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.95439434 0.04560571]\n",
            " [0.9352111  0.06478888]\n",
            " [0.8093839  0.19061612]\n",
            " [0.7897753  0.21022473]\n",
            " [0.95482874 0.0451712 ]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.07057702 0.92942303]\n",
            " [0.02506326 0.9749367 ]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.03863131 0.9613687 ]\n",
            " [0.04366032 0.95633966]\n",
            " [0.7897753  0.21022473]\n",
            " [0.9401946  0.05980542]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.04931042 0.95068955]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.61455226 0.38544765]\n",
            " [0.04931042 0.95068955]\n",
            " [0.87203    0.12797001]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.5247715  0.4752285 ]\n",
            " [0.08729207 0.9127079 ]\n",
            " [0.03416088 0.9658391 ]\n",
            " [0.74624616 0.25375387]\n",
            " [0.6145523  0.38544765]\n",
            " [0.03019153 0.9698085 ]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.07057702 0.92942303]\n",
            " [0.43336046 0.56663954]\n",
            " [0.95482874 0.0451712 ]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.1496386  0.8503614 ]\n",
            " [0.03019153 0.9698085 ]\n",
            " [0.94446415 0.05553583]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.03863131 0.9613687 ]\n",
            " [0.95511633 0.04488373]\n",
            " [0.9536613  0.04633873]\n",
            " [0.03416088 0.9658391 ]\n",
            " [0.94446415 0.05553583]\n",
            " [0.9549881  0.04501184]\n",
            " [0.0410722  0.95892775]\n",
            " [0.03863131 0.9613687 ]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.10863506 0.89136493]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.26839206 0.731608  ]\n",
            " [0.9500513  0.04994874]\n",
            " [0.34627017 0.65372986]\n",
            " [0.3744825  0.6255175 ]\n",
            " [0.43336046 0.56663954]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.64311945 0.35688058]\n",
            " [0.9552593  0.04474064]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.9478152  0.05218486]\n",
            " [0.1496386  0.8503614 ]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.94446415 0.05553583]\n",
            " [0.9018236  0.09817638]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.90959454 0.09040547]\n",
            " [0.9538088  0.04619123]\n",
            " [0.1496386  0.8503614 ]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.64311945 0.35688058]\n",
            " [0.49418208 0.50581795]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.04640362 0.95359635]\n",
            " [0.02667065 0.97332937]\n",
            " [0.6145523  0.38544765]\n",
            " [0.07847834 0.92152166]\n",
            " [0.9549881  0.04501184]\n",
            " [0.61455226 0.38544765]\n",
            " [0.8831716  0.11682831]\n",
            " [0.9018236  0.09817638]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.20260097 0.7973991 ]\n",
            " [0.24504127 0.75495875]\n",
            " [0.6971599  0.30284008]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.95482874 0.0451712 ]\n",
            " [0.02667065 0.97332937]\n",
            " [0.04931042 0.95068955]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.09733439 0.9026656 ]\n",
            " [0.87203    0.12797001]\n",
            " [0.24504127 0.75495875]\n",
            " [0.04640362 0.95359635]\n",
            " [0.9530667  0.0469333 ]\n",
            " [0.26839206 0.731608  ]\n",
            " [0.8597065  0.14029345]\n",
            " [0.9018236  0.09817638]\n",
            " [0.9549881  0.04501184]\n",
            " [0.95212114 0.0478789 ]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.24504127 0.75495875]\n",
            " [0.24504127 0.75495875]\n",
            " [0.95336497 0.04663506]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.04366032 0.95633966]\n",
            " [0.87203    0.12797001]\n",
            " [0.03863131 0.9613687 ]\n",
            " [0.03416088 0.9658391 ]\n",
            " [0.8275628  0.17243716]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.6971599  0.30284008]\n",
            " [0.9478152  0.05218486]\n",
            " [0.5247715  0.4752285 ]\n",
            " [0.5247715  0.47522852]\n",
            " [0.9549728  0.04502725]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.10863506 0.89136493]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9478152  0.05218486]\n",
            " [0.34627017 0.65372986]\n",
            " [0.07057702 0.92942303]\n",
            " [0.9168071  0.08319291]\n",
            " [0.9554998  0.04450024]\n",
            " [0.8275628  0.17243716]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.8093839  0.19061612]\n",
            " [0.95439434 0.04560571]\n",
            " [0.9168071  0.08319291]\n",
            " [0.49418208 0.50581795]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.04640362 0.95359635]\n",
            " [0.95424855 0.04575142]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.72237045 0.27762955]\n",
            " [0.9168071  0.08319291]\n",
            " [0.8093839  0.19061612]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.9500513  0.04994874]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.9549728  0.04502725]\n",
            " [0.61455226 0.38544765]\n",
            " [0.95439434 0.04560571]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.0410722  0.95892775]\n",
            " [0.8597065  0.14029345]\n",
            " [0.9401946  0.05980542]\n",
            " [0.03416088 0.9658391 ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.34627017 0.65372986]\n",
            " [0.95468444 0.0453156 ]\n",
            " [0.9352111  0.06478888]\n",
            " [0.8443415  0.15565851]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.20260097 0.7973991 ]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.03019153 0.9698085 ]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.94446415 0.05553583]\n",
            " [0.24504127 0.75495875]\n",
            " [0.9536613  0.04633873]\n",
            " [0.0410722  0.95892775]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.9168071  0.08319291]\n",
            " [0.43336046 0.56663954]\n",
            " [0.9296822  0.07031785]\n",
            " [0.9168071  0.08319291]\n",
            " [0.9549728  0.04502725]\n",
            " [0.89331627 0.10668368]\n",
            " [0.07847834 0.92152166]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.04640362 0.95359635]\n",
            " [0.04931042 0.95068955]\n",
            " [0.04366032 0.95633966]\n",
            " [0.9018236  0.09817638]\n",
            " [0.04640362 0.95359635]\n",
            " [0.95511633 0.04488373]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.90959454 0.09040547]\n",
            " [0.1496386  0.8503614 ]\n",
            " [0.9296822  0.07031785]\n",
            " [0.43336046 0.56663954]\n",
            " [0.9500513  0.04994874]\n",
            " [0.87203    0.12797001]\n",
            " [0.03863131 0.9613687 ]\n",
            " [0.9500513  0.04994874]\n",
            " [0.9530667  0.0469333 ]\n",
            " [0.67070365 0.32929632]\n",
            " [0.0410722  0.95892775]\n",
            " [0.9536613  0.04633873]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.5247715  0.4752285 ]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.9530667  0.0469333 ]\n",
            " [0.9296822  0.07031785]\n",
            " [0.7897753  0.21022473]\n",
            " [0.8831716  0.11682831]\n",
            " [0.67070365 0.32929632]\n",
            " [0.9549881  0.04501184]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9234926  0.07650737]\n",
            " [0.94446415 0.05553583]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.04931042 0.95068955]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.89331627 0.10668368]\n",
            " [0.3744825  0.6255175 ]\n",
            " [0.9554998  0.04450024]\n",
            " [0.95511633 0.04488373]\n",
            " [0.9234926  0.07650737]\n",
            " [0.3744825  0.6255175 ]\n",
            " [0.03019153 0.9698085 ]\n",
            " [0.9535133  0.04648669]\n",
            " [0.8275628  0.17243716]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.95453954 0.04546043]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.95212114 0.0478789 ]\n",
            " [0.8093839  0.19061612]\n",
            " [0.9554998  0.04450024]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9530667  0.0469333 ]\n",
            " [0.24504127 0.75495875]\n",
            " [0.16589588 0.83410406]\n",
            " [0.05564915 0.94435084]\n",
            " [0.64311945 0.35688058]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.95540196 0.044598  ]\n",
            " [0.64311945 0.35688058]\n",
            " [0.10863506 0.89136493]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.03019153 0.9698085 ]\n",
            " [0.24504127 0.75495875]\n",
            " [0.67070365 0.32929632]\n",
            " [0.95212114 0.0478789 ]\n",
            " [0.9352111  0.06478888]\n",
            " [0.07057702 0.92942303]\n",
            " [0.94446415 0.05553583]\n",
            " [0.12107182 0.8789281 ]\n",
            " [0.9168071  0.08319291]\n",
            " [0.9552593  0.04474064]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.05916241 0.9408376 ]\n",
            " [0.95511633 0.04488373]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.9401946  0.05980542]\n",
            " [0.95370024 0.04629977]\n",
            " [0.09733439 0.9026656 ]\n",
            " [0.95540196 0.044598  ]\n",
            " [0.04931042 0.95068955]\n",
            " [0.90959454 0.09040547]\n",
            " [0.6145523  0.38544765]\n",
            " [0.9168071  0.08319291]\n",
            " [0.9234926  0.07650737]\n",
            " [0.9539559  0.04604419]\n",
            " [0.8443415  0.15565853]\n",
            " [0.9535133  0.04648668]\n",
            " [0.5247715  0.47522852]\n",
            " [0.9500513  0.04994874]\n",
            " [0.76872593 0.23127408]\n",
            " [0.26839206 0.731608  ]\n",
            " [0.02667065 0.97332937]\n",
            " [0.95321614 0.04678391]\n",
            " [0.95453954 0.04546043]\n",
            " [0.03416088 0.9658391 ]\n",
            " [0.04640362 0.95359635]\n",
            " [0.07847834 0.92152166]\n",
            " [0.9296822  0.07031785]\n",
            " [0.16589588 0.83410406]\n",
            " [0.5551763  0.44482362]\n",
            " [0.06417769 0.9358223 ]\n",
            " [0.18353814 0.8164618 ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9552593  0.04474064]\n",
            " [0.9018236  0.09817638]\n",
            " [0.95336497 0.04663506]\n",
            " [0.10863506 0.89136493]\n",
            " [0.3744825  0.6255175 ]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9554998  0.04450024]\n",
            " [0.6971599  0.30284008]\n",
            " [0.76872593 0.23127408]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.95321614 0.04678391]\n",
            " [0.9478152  0.05218486]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.9535133  0.04648668]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.9549728  0.04502725]\n",
            " [0.8443415  0.15565853]\n",
            " [0.04366032 0.95633966]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.7897753  0.21022473]\n",
            " [0.7897753  0.21022473]\n",
            " [0.05564915 0.94435084]\n",
            " [0.8443415  0.15565851]\n",
            " [0.61455226 0.38544765]\n",
            " [0.24504127 0.75495875]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.67070365 0.32929632]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.8275628  0.17243716]\n",
            " [0.9549728  0.04502725]\n",
            " [0.8275628  0.17243716]\n",
            " [0.07847834 0.92152166]\n",
            " [0.5851736  0.4148264 ]\n",
            " [0.5247715  0.47522852]\n",
            " [0.6971599  0.30284008]\n",
            " [0.64311945 0.35688058]\n",
            " [0.94446415 0.05553583]\n",
            " [0.95370024 0.04629977]\n",
            " [0.04931042 0.95068955]\n",
            " [0.9554998  0.04450024]\n",
            " [0.04366032 0.95633966]\n",
            " [0.9018236  0.09817638]\n",
            " [0.95370024 0.04629977]\n",
            " [0.3744825  0.6255175 ]\n",
            " [0.87203    0.12797001]\n",
            " [0.76872593 0.23127408]\n",
            " [0.9539559  0.04604419]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.10863506 0.89136493]\n",
            " [0.9168071  0.08319291]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.02667065 0.97332937]\n",
            " [0.06417769 0.9358223 ]\n",
            " [0.95453954 0.04546043]\n",
            " [0.9538088  0.04619123]\n",
            " [0.04366032 0.95633966]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.8093839  0.19061612]\n",
            " [0.6971599  0.30284008]\n",
            " [0.06417769 0.9358223 ]\n",
            " [0.72237045 0.27762955]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.24504127 0.75495875]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.9536613  0.04633873]\n",
            " [0.05564915 0.94435084]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.29310408 0.7068959 ]\n",
            " [0.89331627 0.10668368]\n",
            " [0.07847834 0.92152166]\n",
            " [0.9539559  0.04604419]\n",
            " [0.03632998 0.96367   ]\n",
            " [0.10863506 0.89136493]\n",
            " [0.34627017 0.65372986]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.64311945 0.35688058]\n",
            " [0.24504127 0.75495875]\n",
            " [0.67070365 0.32929632]\n",
            " [0.31909904 0.680901  ]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.13471714 0.8652829 ]\n",
            " [0.9539559  0.04604419]\n",
            " [0.87203    0.12797001]\n",
            " [0.9549728  0.04502725]\n",
            " [0.10863506 0.89136493]\n",
            " [0.9549881  0.04501184]\n",
            " [0.74624616 0.25375387]\n",
            " [0.12107182 0.8789281 ]\n",
            " [0.40357426 0.5964257 ]\n",
            " [0.9500513  0.04994874]\n",
            " [0.02506326 0.9749367 ]\n",
            " [0.9234926  0.07650737]\n",
            " [0.8093839  0.19061612]\n",
            " [0.9018236  0.09817638]\n",
            " [0.64311945 0.35688058]\n",
            " [0.12107182 0.8789281 ]\n",
            " [0.95424855 0.04575142]\n",
            " [0.02667065 0.97332937]\n",
            " [0.02837813 0.9716219 ]\n",
            " [0.9538088  0.04619123]\n",
            " [0.8831716  0.11682831]\n",
            " [0.34627017 0.65372986]\n",
            " [0.9549881  0.04501184]\n",
            " [0.22310255 0.7768975 ]\n",
            " [0.08729207 0.9127079 ]\n",
            " [0.6145523  0.38544765]\n",
            " [0.07847834 0.92152166]\n",
            " [0.9555221  0.0444779 ]\n",
            " [0.43336046 0.56663954]\n",
            " [0.05238929 0.9476107 ]\n",
            " [0.07847834 0.92152166]\n",
            " [0.03211696 0.967883  ]\n",
            " [0.95370024 0.04629977]\n",
            " [0.95212114 0.0478789 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T76sfEIiJHqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e738002-b7b1-4112-f842-97db6b02b2d6"
      },
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=1)\r\n",
        "print(rounded_predictions.shape)\r\n",
        "print(rounded_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420,)\n",
            "[0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
            " 1 0 1 1 0 1 0 1 1 1 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2JWTPGNJicN"
      },
      "source": [
        "##Create a Confusion Matrix for Neural Network Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OqfAusjJk0B"
      },
      "source": [
        "%matplotlib inline\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import itertools\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6-AFd0sKZ3l",
        "outputId": "c0771154-aa95-45f7-ce99-5c2b0d506932"
      },
      "source": [
        "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)\r\n",
        "print(test_labels.shape)\r\n",
        "print(rounded_predictions.shape)\r\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420,)\n",
            "(420,)\n",
            "[[198  12]\n",
            " [ 10 200]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO7RBENvLPwp"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\r\n",
        "  '''\r\n",
        "  This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`\r\n",
        "  '''\r\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "  plt.title(title)\r\n",
        "  plt.colorbar()\r\n",
        "  tick_marks = np.arange(len(classes))\r\n",
        "  plt.xticks(tick_marks, classes)\r\n",
        "\r\n",
        "  if normalize:\r\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "    print('Normalized confusion matrix')\r\n",
        "  else:\r\n",
        "    print('Confusion matrix, without normalization')\r\n",
        "  \r\n",
        "  print(cm)\r\n",
        "\r\n",
        "  thresh = cm.max() / 2. \r\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "    plt.text(j, i, cm[i, j],\r\n",
        "              horizontalalignment='center',\r\n",
        "              color='white' if cm[i,j] > thresh else 'black')\r\n",
        "  \r\n",
        "  plt.tight_layout()\r\n",
        "  plt.ylabel('True label')\r\n",
        "  plt.xlabel('Predicated label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "c3JnFKm-N8OQ",
        "outputId": "760938d3-f954-4ab3-9d88-d8219ce96320"
      },
      "source": [
        "cm_plot_labels = ['no_side_effects', 'had_side_effects']\r\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[198  12]\n",
            " [ 10 200]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfBqurSqQsRn"
      },
      "source": [
        "##Save and Load a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nGjYTmBQvSc",
        "outputId": "1c77a83d-154e-492f-ce88-bd0c128e9be4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWSioJldRIA0"
      },
      "source": [
        "### 1. model.save()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj_zszegRNFT"
      },
      "source": [
        "# Checks first to see if file exists already.\r\n",
        "# If not, the model is saved to disk\r\n",
        "import os.path\r\n",
        "if os.path.isfile('models/medical_trial_model.h5') is False:\r\n",
        "  model.save('models/medical_trial_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF4NCr15R1O9"
      },
      "source": [
        "This save function saves:\r\n",
        "- The architecture of the model, allowing to re-create the model.\r\n",
        "- The weights of the model.\r\n",
        "- The training configuration (loss, optimizer)\r\n",
        "- The state of the optimizer, allowing to resume training exactly where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJJTrNQwSSbD"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "new_model = load_model('models/medical_trial_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytFRrZOUSopU",
        "outputId": "f2874dd5-4bbc-4fe9-b371-1268afd8864e"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv6QKMZ5S5Ny",
        "outputId": "6091c08d-839f-4c9c-b99f-76bffa54c4fe"
      },
      "source": [
        "new_model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.5751344 ,  0.6264635 , -0.02298748, -0.40958884,  0.01573362,\n",
              "          0.18426087, -0.2795817 ,  0.07230411, -0.42508942, -0.06087071,\n",
              "          0.68343514,  0.20122218,  0.6978781 , -0.19365343, -0.3964309 ,\n",
              "          0.23490974]], dtype=float32),\n",
              " array([-0.11607415, -0.16784927,  0.        ,  0.        , -0.01583819,\n",
              "        -0.07425104,  0.        ,  0.2620456 ,  0.        ,  0.        ,\n",
              "        -0.1505774 , -0.08042179, -0.14691965,  0.        ,  0.        ,\n",
              "         0.09477514], dtype=float32),\n",
              " array([[-0.17008209,  0.24316873, -0.22481093,  0.12887701, -0.31790325,\n",
              "         -0.29881012,  0.5304096 ,  0.16356708,  0.05930667,  0.21665438,\n",
              "         -0.05234507,  0.17022678, -0.2948548 ,  0.0176103 , -0.27781102,\n",
              "         -0.0626021 ,  0.20192778, -0.00460312,  0.15623891,  0.04747446,\n",
              "          0.4229497 , -0.3775816 , -0.3001887 ,  0.13622305, -0.19796872,\n",
              "         -0.3833243 , -0.16315092, -0.34158   ,  0.21720771, -0.11649987,\n",
              "          0.25875565,  0.36359397],\n",
              "        [-0.2570324 ,  0.5545426 , -0.26763624, -0.41549736, -0.05065051,\n",
              "          0.33068523,  0.5754635 ,  0.23901373,  0.46153718, -0.04987749,\n",
              "          0.45773098,  0.25025895,  0.09540412,  0.25674284, -0.2670176 ,\n",
              "          0.3312418 , -0.38092375, -0.14266649, -0.09440437, -0.15247728,\n",
              "          0.40687945, -0.17827   ,  0.27849433, -0.3302355 , -0.17880401,\n",
              "         -0.46711594, -0.04793078,  0.06544011,  0.32577714, -0.34929824,\n",
              "         -0.32997215,  0.47929576],\n",
              "        [ 0.2690976 , -0.06159982, -0.32175636, -0.2817028 ,  0.29148307,\n",
              "          0.302753  ,  0.25382313,  0.07652619,  0.22729161,  0.03424373,\n",
              "          0.20115277, -0.0152742 ,  0.15444162,  0.01947278,  0.1625621 ,\n",
              "         -0.09415731,  0.30609116,  0.30791518, -0.35052234,  0.2617328 ,\n",
              "         -0.2499131 , -0.18956633,  0.35129037, -0.02373189,  0.09266979,\n",
              "         -0.06330523,  0.28579685,  0.18172804, -0.05674374, -0.04260272,\n",
              "          0.15718982,  0.20991161],\n",
              "        [-0.28413433, -0.27885097, -0.09795636,  0.15872577,  0.12671366,\n",
              "          0.2991328 , -0.19836776, -0.24833614,  0.1982995 , -0.09924975,\n",
              "          0.16923985,  0.1978291 ,  0.11451584, -0.3415208 , -0.27612102,\n",
              "         -0.28154245, -0.20147677, -0.25867224, -0.03669676,  0.27324745,\n",
              "         -0.30243567, -0.28099042, -0.00515667, -0.31983194,  0.14882389,\n",
              "          0.09478572, -0.19869635, -0.3393801 ,  0.15092012,  0.22200981,\n",
              "          0.28133103, -0.3066253 ],\n",
              "        [-0.09419912,  0.18949535,  0.14490098,  0.3207751 ,  0.05601805,\n",
              "         -0.07849379, -0.29145914,  0.01031935, -0.20916975,  0.11486897,\n",
              "          0.2640656 , -0.01107152, -0.01522496,  0.30220824,  0.09893773,\n",
              "         -0.03151943,  0.22277029,  0.00743473,  0.06027986, -0.13164665,\n",
              "          0.02492758, -0.22929351,  0.06630761,  0.08890303, -0.08497387,\n",
              "         -0.08079364, -0.2559026 , -0.13763803,  0.21164279, -0.11684328,\n",
              "         -0.10339347, -0.14697008],\n",
              "        [-0.1482421 ,  0.26870072, -0.4405204 , -0.42493817, -0.27057946,\n",
              "          0.21149875,  0.1286431 ,  0.4391608 ,  0.4568257 , -0.04107007,\n",
              "          0.3562111 ,  0.2404    , -0.2730257 , -0.09746087,  0.15991782,\n",
              "         -0.07860421,  0.21274272,  0.22454174,  0.18891571,  0.22079888,\n",
              "          0.08836226, -0.47727785, -0.3376883 , -0.24933487, -0.34966636,\n",
              "         -0.00952298, -0.28455874, -0.1996199 , -0.00633119,  0.03068113,\n",
              "         -0.10737287,  0.25589836],\n",
              "        [-0.17383324, -0.06198436, -0.02547634,  0.13540527, -0.3424675 ,\n",
              "         -0.1753835 , -0.05222255, -0.05429173,  0.32615462, -0.32309133,\n",
              "          0.04866022,  0.03809494, -0.24776648,  0.23818496, -0.2862711 ,\n",
              "          0.2757974 , -0.12876064, -0.22892314,  0.16207519,  0.15477881,\n",
              "          0.22271803, -0.06523025, -0.34263667,  0.18870619,  0.11919609,\n",
              "         -0.20970754, -0.16271381, -0.16917618, -0.27066985, -0.24821366,\n",
              "          0.32956246, -0.3127442 ],\n",
              "        [-0.0420709 , -0.16000687,  0.44243735,  0.23153523,  0.05807981,\n",
              "          0.00875533,  0.04819268,  0.162801  ,  0.33292505, -0.17713976,\n",
              "          0.2211399 ,  0.01963709, -0.33496696,  0.03624486, -0.06617958,\n",
              "          0.1263931 , -0.09637076, -0.18248455,  0.2210992 , -0.20913866,\n",
              "          0.04772121,  0.15302867, -0.40322158,  0.3822972 ,  0.24578793,\n",
              "          0.03763343, -0.00731559, -0.05828199, -0.20753852, -0.32751912,\n",
              "         -0.04383203,  0.10193293],\n",
              "        [-0.06540695,  0.15696362, -0.05112058,  0.05317432, -0.0248754 ,\n",
              "          0.21034244,  0.09145343,  0.3024766 , -0.11827914, -0.29651833,\n",
              "         -0.02732676,  0.30952492, -0.17805535, -0.3011924 , -0.25963917,\n",
              "          0.19158962,  0.00484326, -0.04930413,  0.18126509, -0.34928524,\n",
              "         -0.3167006 ,  0.34849426, -0.20724304,  0.00984591, -0.27787584,\n",
              "         -0.11296518,  0.09514678, -0.15390663, -0.34853217,  0.26337883,\n",
              "         -0.00935566, -0.0709748 ],\n",
              "        [-0.30334342, -0.20764336,  0.29854223,  0.23723784, -0.27102438,\n",
              "          0.14838436,  0.17479047,  0.24630806, -0.00549123,  0.26655927,\n",
              "         -0.01140267,  0.2342619 , -0.166088  , -0.19635879,  0.26935014,\n",
              "         -0.08025241, -0.23125882,  0.2538171 ,  0.2043725 ,  0.19884351,\n",
              "         -0.22121076, -0.20453654, -0.01859155,  0.29533097,  0.07390162,\n",
              "          0.18665919, -0.23272368,  0.06247157,  0.04201627, -0.23192954,\n",
              "         -0.16534832,  0.1634138 ],\n",
              "        [-0.11988911,  0.09824853, -0.06621518, -0.13058804, -0.01372301,\n",
              "         -0.18212116,  0.08375858,  0.55581284,  0.59435016,  0.04160872,\n",
              "          0.50119346, -0.03285057, -0.22344548, -0.13811405, -0.350842  ,\n",
              "          0.41811842, -0.03047359, -0.21607171,  0.49869362,  0.05224914,\n",
              "          0.4168425 ,  0.12153422, -0.01301306, -0.38319662, -0.1390759 ,\n",
              "         -0.02426359, -0.3421894 , -0.44533277,  0.5638437 , -0.34597385,\n",
              "         -0.42794728,  0.43839267],\n",
              "        [-0.01595569,  0.7261748 , -0.19270775, -0.12999922, -0.3202562 ,\n",
              "          0.24521804,  0.27864116,  0.1174057 ,  0.10318587, -0.16950417,\n",
              "          0.6921067 , -0.2273671 ,  0.11594051,  0.24090062,  0.08002182,\n",
              "          0.27228117, -0.01236871,  0.13811511,  0.23269908,  0.03672024,\n",
              "          0.37736285, -0.37872228, -0.08267563, -0.29627523, -0.23143707,\n",
              "         -0.21064705,  0.05674139, -0.47975108,  0.26195493, -0.3199074 ,\n",
              "         -0.23068996,  0.50551295],\n",
              "        [-0.19687821,  0.5043403 , -0.12975566, -0.24748284,  0.31277537,\n",
              "          0.08246506,  0.31448108,  0.55797464, -0.07581659, -0.21799909,\n",
              "          0.11513477, -0.26496574, -0.29082775,  0.06980945,  0.12082579,\n",
              "          0.34964356,  0.17756423, -0.10669396,  0.37277955,  0.18903294,\n",
              "          0.53203714, -0.29027155,  0.2529752 , -0.1299801 , -0.3383254 ,\n",
              "         -0.08262937,  0.3026567 ,  0.19904518,  0.5393391 ,  0.15220442,\n",
              "         -0.19666563,  0.47404057],\n",
              "        [-0.13162401,  0.08107385, -0.15700342,  0.26308188, -0.241806  ,\n",
              "         -0.12366475, -0.07899383, -0.04423869,  0.20077834,  0.1432352 ,\n",
              "          0.22006199,  0.05984077,  0.28581086,  0.18105999, -0.1588073 ,\n",
              "         -0.02344856, -0.33265132,  0.3292847 ,  0.01347122,  0.10142404,\n",
              "         -0.30623612, -0.17366146,  0.13556272, -0.09697974,  0.1462118 ,\n",
              "         -0.13958286,  0.25408664, -0.04927415, -0.2772074 ,  0.18621859,\n",
              "         -0.14724608, -0.06489846],\n",
              "        [ 0.11082917, -0.18030472,  0.155341  ,  0.22591677,  0.27008417,\n",
              "         -0.0818271 , -0.14728081, -0.15634668,  0.2901738 ,  0.2355257 ,\n",
              "         -0.14016221,  0.2312074 ,  0.20560351,  0.29994008, -0.00499862,\n",
              "         -0.20159444, -0.30490613,  0.14613307,  0.24967596,  0.33406588,\n",
              "          0.31843403,  0.2826452 ,  0.20822898, -0.10946018, -0.33552405,\n",
              "          0.01975262,  0.24502203,  0.22602543,  0.23573336,  0.01086411,\n",
              "          0.3021182 ,  0.3002036 ],\n",
              "        [ 0.17716707, -0.11516187, -0.2848444 ,  0.0148473 , -0.08409724,\n",
              "         -0.06854291,  0.10364378,  0.05678389,  0.43264347, -0.11373826,\n",
              "          0.22741896, -0.09974636, -0.04260761, -0.3574934 ,  0.28290582,\n",
              "          0.2482456 ,  0.08171009, -0.10047951,  0.23441689, -0.25997457,\n",
              "          0.45448402,  0.14922638,  0.06856046,  0.03258308,  0.20595619,\n",
              "          0.34523764,  0.23940665,  0.05211561, -0.17532156, -0.2300531 ,\n",
              "          0.16922727, -0.01321327]], dtype=float32),\n",
              " array([-0.01436091, -0.05880781,  0.24871267,  0.22263718, -0.00884125,\n",
              "        -0.00569449, -0.10170668, -0.10579859, -0.1518153 , -0.00110853,\n",
              "        -0.11252835, -0.02048133,  0.        , -0.03026419, -0.02304093,\n",
              "        -0.10239998, -0.01682471, -0.00054757, -0.11381074, -0.02356915,\n",
              "        -0.10684126,  0.24704465, -0.03374549,  0.20095664,  0.25346407,\n",
              "         0.259811  , -0.0208189 ,  0.24233744, -0.06291659,  0.        ,\n",
              "         0.2709155 , -0.09446589], dtype=float32),\n",
              " array([[-0.08190447,  0.27116   ],\n",
              "        [-0.5044593 ,  0.05624218],\n",
              "        [ 0.41754007, -0.67822796],\n",
              "        [ 0.79837096, -0.47769842],\n",
              "        [-0.16788419,  0.41547316],\n",
              "        [ 0.20529276, -0.28713986],\n",
              "        [-0.29105908,  0.21911654],\n",
              "        [-0.38533166,  0.07869138],\n",
              "        [-0.43813705,  0.08591175],\n",
              "        [-0.26470053,  0.05302493],\n",
              "        [-0.57023245,  0.00886671],\n",
              "        [-0.00251178, -0.37345827],\n",
              "        [-0.11177501,  0.07738811],\n",
              "        [ 0.3281121 , -0.24868216],\n",
              "        [-0.05812963,  0.35975778],\n",
              "        [-0.04361863,  0.20260379],\n",
              "        [ 0.1108361 , -0.29683265],\n",
              "        [-0.33347476,  0.19221073],\n",
              "        [-0.43277687,  0.17008522],\n",
              "        [ 0.19077094, -0.35425907],\n",
              "        [ 0.03068492,  0.6166264 ],\n",
              "        [ 0.44163758, -0.72997504],\n",
              "        [ 0.35484442, -0.11880933],\n",
              "        [ 0.8075811 , -0.834531  ],\n",
              "        [ 0.6939112 , -0.3790398 ],\n",
              "        [ 0.17330453, -0.7500217 ],\n",
              "        [-0.23428367, -0.18890195],\n",
              "        [ 0.52021915, -0.72624284],\n",
              "        [-0.08178862,  0.5157294 ],\n",
              "        [ 0.3477073 , -0.33036134],\n",
              "        [ 0.7247573 , -0.24360184],\n",
              "        [-0.39323112,  0.18344231]], dtype=float32),\n",
              " array([ 0.11396816, -0.11396817], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pz8XAceTNF6",
        "outputId": "533d0115-9263-43c9-dbd6-f18ac048f092"
      },
      "source": [
        "new_model.optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fee4de6a9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt5rrPbWTU6q"
      },
      "source": [
        "### 2. model.to_json()\r\n",
        "If you only need to same the architecture of a model, and not its weights or its training configuration, you can use the following function to save the architecture only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqIFvhSpTxgl",
        "outputId": "0c1af76d-d93b-4970-b017-be4d86e16973"
      },
      "source": [
        "# save as JSON\r\n",
        "json_string = model.to_json()\r\n",
        "print(json_string)\r\n",
        "\r\n",
        "# save as YAML\r\n",
        "yaml_string = model.to_yaml()\r\n",
        "print(yaml_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}\n",
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "  layers:\n",
            "  - class_name: InputLayer\n",
            "    config:\n",
            "      batch_input_shape: !!python/tuple [null, 1]\n",
            "      dtype: float32\n",
            "      name: dense_input\n",
            "      ragged: false\n",
            "      sparse: false\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      batch_input_shape: !!python/tuple [null, 1]\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense\n",
            "      trainable: true\n",
            "      units: 16\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_1\n",
            "      trainable: true\n",
            "      units: 32\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: softmax\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_2\n",
            "      trainable: true\n",
            "      units: 2\n",
            "      use_bias: true\n",
            "  name: sequential\n",
            "keras_version: 2.4.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCJoIjHeTUFp"
      },
      "source": [
        "# model reconstruction from JSON\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "model_architecture = model_from_json(json_string)\r\n",
        "\r\n",
        "# model reconstruction from YAML\r\n",
        "# from tensorflow.keras.models import model_from_yaml\r\n",
        "# model_architecture = model_from_yaml(yaml_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xofejL4GV80R",
        "outputId": "0c421a62-8265-4a32-e272-77799ce15116"
      },
      "source": [
        "model_architecture.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD9qHSlmWCQJ"
      },
      "source": [
        "### 3. model.save_weights()\r\n",
        "If you only need to save the weights of a model, you can use the following function to save the weights only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbVuaD2FWfqV"
      },
      "source": [
        "# Check first to see if file exists already.\r\n",
        "# If not, the weights are saved to disk\r\n",
        "import os.path\r\n",
        "if os.path.isfile('models/my_model_weights.h5') is False:\r\n",
        "  model.save_weights('models/my_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ioG6hAQGUp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwfWDaCWW-64"
      },
      "source": [
        "model2 = Sequential([\r\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\r\n",
        "    Dense(units=32, activation='relu'),\r\n",
        "    Dense(units=2, activation='softmax')                  \r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT0GAgDxXx9c"
      },
      "source": [
        "model2.load_weights('models/my_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHADFsUgWKsw",
        "outputId": "036e1ceb-fa0d-4f9e-a823-b86d6c759880"
      },
      "source": [
        "model2.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.5751344 ,  0.6264635 , -0.02298748, -0.40958884,  0.01573362,\n",
              "          0.18426087, -0.2795817 ,  0.07230411, -0.42508942, -0.06087071,\n",
              "          0.68343514,  0.20122218,  0.6978781 , -0.19365343, -0.3964309 ,\n",
              "          0.23490974]], dtype=float32),\n",
              " array([-0.11607415, -0.16784927,  0.        ,  0.        , -0.01583819,\n",
              "        -0.07425104,  0.        ,  0.2620456 ,  0.        ,  0.        ,\n",
              "        -0.1505774 , -0.08042179, -0.14691965,  0.        ,  0.        ,\n",
              "         0.09477514], dtype=float32),\n",
              " array([[-0.17008209,  0.24316873, -0.22481093,  0.12887701, -0.31790325,\n",
              "         -0.29881012,  0.5304096 ,  0.16356708,  0.05930667,  0.21665438,\n",
              "         -0.05234507,  0.17022678, -0.2948548 ,  0.0176103 , -0.27781102,\n",
              "         -0.0626021 ,  0.20192778, -0.00460312,  0.15623891,  0.04747446,\n",
              "          0.4229497 , -0.3775816 , -0.3001887 ,  0.13622305, -0.19796872,\n",
              "         -0.3833243 , -0.16315092, -0.34158   ,  0.21720771, -0.11649987,\n",
              "          0.25875565,  0.36359397],\n",
              "        [-0.2570324 ,  0.5545426 , -0.26763624, -0.41549736, -0.05065051,\n",
              "          0.33068523,  0.5754635 ,  0.23901373,  0.46153718, -0.04987749,\n",
              "          0.45773098,  0.25025895,  0.09540412,  0.25674284, -0.2670176 ,\n",
              "          0.3312418 , -0.38092375, -0.14266649, -0.09440437, -0.15247728,\n",
              "          0.40687945, -0.17827   ,  0.27849433, -0.3302355 , -0.17880401,\n",
              "         -0.46711594, -0.04793078,  0.06544011,  0.32577714, -0.34929824,\n",
              "         -0.32997215,  0.47929576],\n",
              "        [ 0.2690976 , -0.06159982, -0.32175636, -0.2817028 ,  0.29148307,\n",
              "          0.302753  ,  0.25382313,  0.07652619,  0.22729161,  0.03424373,\n",
              "          0.20115277, -0.0152742 ,  0.15444162,  0.01947278,  0.1625621 ,\n",
              "         -0.09415731,  0.30609116,  0.30791518, -0.35052234,  0.2617328 ,\n",
              "         -0.2499131 , -0.18956633,  0.35129037, -0.02373189,  0.09266979,\n",
              "         -0.06330523,  0.28579685,  0.18172804, -0.05674374, -0.04260272,\n",
              "          0.15718982,  0.20991161],\n",
              "        [-0.28413433, -0.27885097, -0.09795636,  0.15872577,  0.12671366,\n",
              "          0.2991328 , -0.19836776, -0.24833614,  0.1982995 , -0.09924975,\n",
              "          0.16923985,  0.1978291 ,  0.11451584, -0.3415208 , -0.27612102,\n",
              "         -0.28154245, -0.20147677, -0.25867224, -0.03669676,  0.27324745,\n",
              "         -0.30243567, -0.28099042, -0.00515667, -0.31983194,  0.14882389,\n",
              "          0.09478572, -0.19869635, -0.3393801 ,  0.15092012,  0.22200981,\n",
              "          0.28133103, -0.3066253 ],\n",
              "        [-0.09419912,  0.18949535,  0.14490098,  0.3207751 ,  0.05601805,\n",
              "         -0.07849379, -0.29145914,  0.01031935, -0.20916975,  0.11486897,\n",
              "          0.2640656 , -0.01107152, -0.01522496,  0.30220824,  0.09893773,\n",
              "         -0.03151943,  0.22277029,  0.00743473,  0.06027986, -0.13164665,\n",
              "          0.02492758, -0.22929351,  0.06630761,  0.08890303, -0.08497387,\n",
              "         -0.08079364, -0.2559026 , -0.13763803,  0.21164279, -0.11684328,\n",
              "         -0.10339347, -0.14697008],\n",
              "        [-0.1482421 ,  0.26870072, -0.4405204 , -0.42493817, -0.27057946,\n",
              "          0.21149875,  0.1286431 ,  0.4391608 ,  0.4568257 , -0.04107007,\n",
              "          0.3562111 ,  0.2404    , -0.2730257 , -0.09746087,  0.15991782,\n",
              "         -0.07860421,  0.21274272,  0.22454174,  0.18891571,  0.22079888,\n",
              "          0.08836226, -0.47727785, -0.3376883 , -0.24933487, -0.34966636,\n",
              "         -0.00952298, -0.28455874, -0.1996199 , -0.00633119,  0.03068113,\n",
              "         -0.10737287,  0.25589836],\n",
              "        [-0.17383324, -0.06198436, -0.02547634,  0.13540527, -0.3424675 ,\n",
              "         -0.1753835 , -0.05222255, -0.05429173,  0.32615462, -0.32309133,\n",
              "          0.04866022,  0.03809494, -0.24776648,  0.23818496, -0.2862711 ,\n",
              "          0.2757974 , -0.12876064, -0.22892314,  0.16207519,  0.15477881,\n",
              "          0.22271803, -0.06523025, -0.34263667,  0.18870619,  0.11919609,\n",
              "         -0.20970754, -0.16271381, -0.16917618, -0.27066985, -0.24821366,\n",
              "          0.32956246, -0.3127442 ],\n",
              "        [-0.0420709 , -0.16000687,  0.44243735,  0.23153523,  0.05807981,\n",
              "          0.00875533,  0.04819268,  0.162801  ,  0.33292505, -0.17713976,\n",
              "          0.2211399 ,  0.01963709, -0.33496696,  0.03624486, -0.06617958,\n",
              "          0.1263931 , -0.09637076, -0.18248455,  0.2210992 , -0.20913866,\n",
              "          0.04772121,  0.15302867, -0.40322158,  0.3822972 ,  0.24578793,\n",
              "          0.03763343, -0.00731559, -0.05828199, -0.20753852, -0.32751912,\n",
              "         -0.04383203,  0.10193293],\n",
              "        [-0.06540695,  0.15696362, -0.05112058,  0.05317432, -0.0248754 ,\n",
              "          0.21034244,  0.09145343,  0.3024766 , -0.11827914, -0.29651833,\n",
              "         -0.02732676,  0.30952492, -0.17805535, -0.3011924 , -0.25963917,\n",
              "          0.19158962,  0.00484326, -0.04930413,  0.18126509, -0.34928524,\n",
              "         -0.3167006 ,  0.34849426, -0.20724304,  0.00984591, -0.27787584,\n",
              "         -0.11296518,  0.09514678, -0.15390663, -0.34853217,  0.26337883,\n",
              "         -0.00935566, -0.0709748 ],\n",
              "        [-0.30334342, -0.20764336,  0.29854223,  0.23723784, -0.27102438,\n",
              "          0.14838436,  0.17479047,  0.24630806, -0.00549123,  0.26655927,\n",
              "         -0.01140267,  0.2342619 , -0.166088  , -0.19635879,  0.26935014,\n",
              "         -0.08025241, -0.23125882,  0.2538171 ,  0.2043725 ,  0.19884351,\n",
              "         -0.22121076, -0.20453654, -0.01859155,  0.29533097,  0.07390162,\n",
              "          0.18665919, -0.23272368,  0.06247157,  0.04201627, -0.23192954,\n",
              "         -0.16534832,  0.1634138 ],\n",
              "        [-0.11988911,  0.09824853, -0.06621518, -0.13058804, -0.01372301,\n",
              "         -0.18212116,  0.08375858,  0.55581284,  0.59435016,  0.04160872,\n",
              "          0.50119346, -0.03285057, -0.22344548, -0.13811405, -0.350842  ,\n",
              "          0.41811842, -0.03047359, -0.21607171,  0.49869362,  0.05224914,\n",
              "          0.4168425 ,  0.12153422, -0.01301306, -0.38319662, -0.1390759 ,\n",
              "         -0.02426359, -0.3421894 , -0.44533277,  0.5638437 , -0.34597385,\n",
              "         -0.42794728,  0.43839267],\n",
              "        [-0.01595569,  0.7261748 , -0.19270775, -0.12999922, -0.3202562 ,\n",
              "          0.24521804,  0.27864116,  0.1174057 ,  0.10318587, -0.16950417,\n",
              "          0.6921067 , -0.2273671 ,  0.11594051,  0.24090062,  0.08002182,\n",
              "          0.27228117, -0.01236871,  0.13811511,  0.23269908,  0.03672024,\n",
              "          0.37736285, -0.37872228, -0.08267563, -0.29627523, -0.23143707,\n",
              "         -0.21064705,  0.05674139, -0.47975108,  0.26195493, -0.3199074 ,\n",
              "         -0.23068996,  0.50551295],\n",
              "        [-0.19687821,  0.5043403 , -0.12975566, -0.24748284,  0.31277537,\n",
              "          0.08246506,  0.31448108,  0.55797464, -0.07581659, -0.21799909,\n",
              "          0.11513477, -0.26496574, -0.29082775,  0.06980945,  0.12082579,\n",
              "          0.34964356,  0.17756423, -0.10669396,  0.37277955,  0.18903294,\n",
              "          0.53203714, -0.29027155,  0.2529752 , -0.1299801 , -0.3383254 ,\n",
              "         -0.08262937,  0.3026567 ,  0.19904518,  0.5393391 ,  0.15220442,\n",
              "         -0.19666563,  0.47404057],\n",
              "        [-0.13162401,  0.08107385, -0.15700342,  0.26308188, -0.241806  ,\n",
              "         -0.12366475, -0.07899383, -0.04423869,  0.20077834,  0.1432352 ,\n",
              "          0.22006199,  0.05984077,  0.28581086,  0.18105999, -0.1588073 ,\n",
              "         -0.02344856, -0.33265132,  0.3292847 ,  0.01347122,  0.10142404,\n",
              "         -0.30623612, -0.17366146,  0.13556272, -0.09697974,  0.1462118 ,\n",
              "         -0.13958286,  0.25408664, -0.04927415, -0.2772074 ,  0.18621859,\n",
              "         -0.14724608, -0.06489846],\n",
              "        [ 0.11082917, -0.18030472,  0.155341  ,  0.22591677,  0.27008417,\n",
              "         -0.0818271 , -0.14728081, -0.15634668,  0.2901738 ,  0.2355257 ,\n",
              "         -0.14016221,  0.2312074 ,  0.20560351,  0.29994008, -0.00499862,\n",
              "         -0.20159444, -0.30490613,  0.14613307,  0.24967596,  0.33406588,\n",
              "          0.31843403,  0.2826452 ,  0.20822898, -0.10946018, -0.33552405,\n",
              "          0.01975262,  0.24502203,  0.22602543,  0.23573336,  0.01086411,\n",
              "          0.3021182 ,  0.3002036 ],\n",
              "        [ 0.17716707, -0.11516187, -0.2848444 ,  0.0148473 , -0.08409724,\n",
              "         -0.06854291,  0.10364378,  0.05678389,  0.43264347, -0.11373826,\n",
              "          0.22741896, -0.09974636, -0.04260761, -0.3574934 ,  0.28290582,\n",
              "          0.2482456 ,  0.08171009, -0.10047951,  0.23441689, -0.25997457,\n",
              "          0.45448402,  0.14922638,  0.06856046,  0.03258308,  0.20595619,\n",
              "          0.34523764,  0.23940665,  0.05211561, -0.17532156, -0.2300531 ,\n",
              "          0.16922727, -0.01321327]], dtype=float32),\n",
              " array([-0.01436091, -0.05880781,  0.24871267,  0.22263718, -0.00884125,\n",
              "        -0.00569449, -0.10170668, -0.10579859, -0.1518153 , -0.00110853,\n",
              "        -0.11252835, -0.02048133,  0.        , -0.03026419, -0.02304093,\n",
              "        -0.10239998, -0.01682471, -0.00054757, -0.11381074, -0.02356915,\n",
              "        -0.10684126,  0.24704465, -0.03374549,  0.20095664,  0.25346407,\n",
              "         0.259811  , -0.0208189 ,  0.24233744, -0.06291659,  0.        ,\n",
              "         0.2709155 , -0.09446589], dtype=float32),\n",
              " array([[-0.08190447,  0.27116   ],\n",
              "        [-0.5044593 ,  0.05624218],\n",
              "        [ 0.41754007, -0.67822796],\n",
              "        [ 0.79837096, -0.47769842],\n",
              "        [-0.16788419,  0.41547316],\n",
              "        [ 0.20529276, -0.28713986],\n",
              "        [-0.29105908,  0.21911654],\n",
              "        [-0.38533166,  0.07869138],\n",
              "        [-0.43813705,  0.08591175],\n",
              "        [-0.26470053,  0.05302493],\n",
              "        [-0.57023245,  0.00886671],\n",
              "        [-0.00251178, -0.37345827],\n",
              "        [-0.11177501,  0.07738811],\n",
              "        [ 0.3281121 , -0.24868216],\n",
              "        [-0.05812963,  0.35975778],\n",
              "        [-0.04361863,  0.20260379],\n",
              "        [ 0.1108361 , -0.29683265],\n",
              "        [-0.33347476,  0.19221073],\n",
              "        [-0.43277687,  0.17008522],\n",
              "        [ 0.19077094, -0.35425907],\n",
              "        [ 0.03068492,  0.6166264 ],\n",
              "        [ 0.44163758, -0.72997504],\n",
              "        [ 0.35484442, -0.11880933],\n",
              "        [ 0.8075811 , -0.834531  ],\n",
              "        [ 0.6939112 , -0.3790398 ],\n",
              "        [ 0.17330453, -0.7500217 ],\n",
              "        [-0.23428367, -0.18890195],\n",
              "        [ 0.52021915, -0.72624284],\n",
              "        [-0.08178862,  0.5157294 ],\n",
              "        [ 0.3477073 , -0.33036134],\n",
              "        [ 0.7247573 , -0.24360184],\n",
              "        [-0.39323112,  0.18344231]], dtype=float32),\n",
              " array([ 0.11396816, -0.11396817], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrtoJ6JNZBB9"
      },
      "source": [
        "##Image Preparation for CNNs\r\n",
        "\r\n",
        "https://github.com/ardamavi/Sign-Language-Digits-Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLLI8Y8_Y8T-"
      },
      "source": [
        "\r\n",
        "https://github.com/learncsds/Keras-ML-DL-DeepLizard/blob/master/DeepLearning.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etB_2F87AMXI"
      },
      "source": [
        "#[Practical Machine Learning Tutorial with Python -  sentdex](https://www.youtube.com/watch?v=OGxgnH8y2NM&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM33OqbLQx0d"
      },
      "source": [
        "##Install Packages\r\n",
        "- ```pip install sklean```\r\n",
        "- ```pip install quandl```\r\n",
        "- ```pip isntall pandas```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPfaXhW-QBE"
      },
      "source": [
        "#[Deep Learning - 3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic2lNYazNi6f"
      },
      "source": [
        "#[Practical Deep Learning for Coders - Full Course from fast.ai and Jeremy Howard](https://www.youtube.com/watch?v=0oyCUWLL_fU&list=RDCMUC8butISFwT-Wl7EV0hUK0BQ&start_radio=1&t=55)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vjCzKlNDF0K"
      },
      "source": [
        "#[Python for Data Science](https://www.youtube.com/watch?v=LHBE6Q9XlzI&t=40900s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2iOeIVsDTdR"
      },
      "source": [
        "#[Learn Data Science Tutorial - Full Course for Beginners](https://www.youtube.com/watch?v=ua-CiDNNj30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by1V0J56Et0x"
      },
      "source": [
        "#[Pytorch for Deep Learning](https://www.youtube.com/watch?v=GIsg-ZUy0MY&t=20s)"
      ]
    }
  ]
}