{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+SivGzqOpQg7Gdf5Q/tZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidzheng66/python3/blob/master/deeplearning/deeplearning-keras-deeplizard-.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5mcjXt94xi"
      },
      "source": [
        "#[Prerequisite: Machine Learning and Deep Learning Fundamental - deeplizard](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWU2iwq0vS0y"
      },
      "source": [
        "##[1. Deep Learning Overview & Machine Learning Introduction](https://www.youtube.com/watch?v=gZmobeGL0Yg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su13EwxuvrWd"
      },
      "source": [
        "##[2. Deep Learning](https://www.youtube.com/watch?v=OT1jslLoCyA&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Riqx8N0pvzLw"
      },
      "source": [
        "##[3. Artificial Neural Network (ANN)](https://www.youtube.com/watch?v=hfK_dvC-avg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEj1AiG2v-K3"
      },
      "source": [
        "##[4. Layers in a Neural Network](https://www.youtube.com/watch?v=FK77zZxaBoI&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=4)\r\n",
        "###Layers in an ANN\r\n",
        "Artificial neural network is typically organized in layers. Different types of layers include:\r\n",
        "* Dense (or fully connected) Layers\r\n",
        "* Convolutional layers\r\n",
        "* Pooling Layers\r\n",
        "* Recurrent Layers\r\n",
        "* Normalization Layers\r\n",
        "* Many others\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9XefjIhwJQu"
      },
      "source": [
        "##[5. Activation Functions in a Neural Network](https://www.youtube.com/watch?v=m0pIlLfpXWE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=5)\r\n",
        "###Activation Functions\r\n",
        "In an artificial neural network, the activation function of a neuron defines the output of that neuro given a set of inputs.\r\n",
        "* Biologically inspired by activity in our brains, where different neurons fire, or are activated, by different stimuli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZrEddwgrYh"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "\r\n",
        "#Way 1 to create a model\r\n",
        "model = Sequential([\r\n",
        "    Dense(5, input_shape=(3,), activation='relu')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClYbS3INhE7z"
      },
      "source": [
        "#Way 2 to create a model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(5, input_shape=(3,)))\r\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvpdGUJkhfL"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "\r\n",
        "#Way 1 to create a model\r\n",
        "model = Sequential([\r\n",
        "    Dense(5, input_shape=(3,), activation='relu'),\r\n",
        "    Dense(2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqFslPPxk2pJ"
      },
      "source": [
        "import numpy as np\r\n",
        "# from scipy import ndimage\r\n",
        "from scipy import misc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# img = np.expand_dims(ndimage.imread('NN.PNG'), 0)\r\n",
        "img = np.expand_dims(misc.imread('NN.PNG'), 0)\r\n",
        "plt.imshow(img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-8_oiL7oXsQ"
      },
      "source": [
        "##[6. Training a Neural Network](https://www.youtube.com/watch?v=sZAlS3_dnk0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ID4nh1MoqIB"
      },
      "source": [
        "###Training\r\n",
        "Solving an optimization proble\r\n",
        "* Optimizing weights\r\n",
        " * with Stochastic Gradient Descent (SGD)\r\n",
        "* Objective: Minimize the loss function\r\n",
        "\r\n",
        "###Learning\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06JwRVlJw6gs"
      },
      "source": [
        "##[7. How a Neural Network Learns](https://www.youtube.com/watch?v=_N5kpSMDf4o&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lomcNRe0xCNC"
      },
      "source": [
        "##[8. Loss in a Neural Network](https://www.youtube.com/watch?v=Skc8nqJirJg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSMjjyC-xKp0"
      },
      "source": [
        "##[9. Learning Rate in a Neural Network](https://www.youtube.com/watch?v=jWT-AX9677k&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NItVj2dExT_S"
      },
      "source": [
        "##[10. Train, Test & Validation Sets](https://www.youtube.com/watch?v=Zi-0rlM4RDs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os2vLwDDxery"
      },
      "source": [
        "##[11. Predicting with a Neural Network](https://www.youtube.com/watch?v=Z0KVRdE_a7Q&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zu0NQUkxneE"
      },
      "source": [
        "##[12. Overfitting in a Neural Network](https://www.youtube.com/watch?v=DEMmkFC6IGM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86EHAHKmxveB"
      },
      "source": [
        "##[13. Underfitting in a Neural Network](https://www.youtube.com/watch?v=0h8lAm5Ki5g&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrfD7QGx5Dh"
      },
      "source": [
        "##[14. Supervised Learning](https://www.youtube.com/watch?v=Quh6x4kG6VY&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL-mW3ExyDCS"
      },
      "source": [
        "##[15. Unsupervised Learning](https://www.youtube.com/watch?v=lEfrr0Yr684&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4FOWKtyKaz"
      },
      "source": [
        "##[16. Semi-supervised Learning](https://www.youtube.com/watch?v=b-yhKUINb7o&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC_rtFEnyRPS"
      },
      "source": [
        "##[17. Data Augmentation](https://www.youtube.com/watch?v=rfM4DaLTkMs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybGFKyXYyX4a"
      },
      "source": [
        "##[18. One-hot Encoding](https://www.youtube.com/watch?v=v_4KWmkwmsU&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIBs1Mihyfxp"
      },
      "source": [
        "##[19. Convolutional Neural Networks](https://www.youtube.com/watch?v=YRhxdVk_sIs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=19)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3JxHihWyqIK"
      },
      "source": [
        "##[20. Visualizing Convolutional Filters from a CNN](https://www.youtube.com/watch?v=cNBBNAxC8l4&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx2am-khy4ai"
      },
      "source": [
        "##[21. Zero Padding in Convolutional Neural Networks](https://www.youtube.com/watch?v=qSTv_m-KFk0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArRuAPNrzD8q"
      },
      "source": [
        "##[22. Max Pooling in Convolutional Neural Networks](https://www.youtube.com/watch?v=ZjM_XQa5s6s&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVWiU3W_zQdO"
      },
      "source": [
        "##[23. Backpropagation | Part 1 - The Intuition](https://www.youtube.com/watch?v=XE3krf3CQls&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I12zwfgSzeV7"
      },
      "source": [
        "##[24. Backpropagation | Part 2 - The Mathematical Notation](https://www.youtube.com/watch?v=2mSysRx-1c0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbuzZSzuztDh"
      },
      "source": [
        "##[25. Backpropagation | Part 3 - Mathematical Observations](https://www.youtube.com/watch?v=G5b4jRBKNxw&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye5UXLt3z9dS"
      },
      "source": [
        "##[26. Backpropagation | Part 4 - Calculating the Gradient](https://www.youtube.com/watch?v=Zr5viAZGndE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=26)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tomxx2w20IRS"
      },
      "source": [
        "##[27. Backpropagation | Part 5 - What Puts the \"back\" in Backprop?](https://www.youtube.com/watch?v=xClK__CqZnQ&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=27)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2x1lbfxR2ZR"
      },
      "source": [
        "##[28. Vanishing & Exploding Gradient | A Problem Resulting from Backprogagation](https://www.youtube.com/watch?v=qO_NLVjD6zE&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=28)\r\n",
        "- Gradient: referrring to the gradient of the loss function with respect to the weights in the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0IzlBUBUi7k"
      },
      "source": [
        "##[29. Weight Initialization | A Way to Reduce the Vanishing Gradient Problem](https://www.youtube.com/watch?v=8krd5qKVw-Q&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA1f8ZVpXeQH"
      },
      "source": [
        "##[30. Bias in an Artificial Neural Network | How Bias Impacts Training](https://www.youtube.com/watch?v=HetFihsXSys&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpgRyhDjgxcI"
      },
      "source": [
        "##[31. Learnable Parameters in an Artificial Neural Network](https://www.youtube.com/watch?v=pg3hJpSopHQ&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=31)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd7diOMEj5wa"
      },
      "source": [
        "##[32. Learnable Parameters in a Convolutional Neural Network (CNN)](https://www.youtube.com/watch?v=gmBfb6LNnZs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MePjTZIMXp_B"
      },
      "source": [
        "##[33. Regularization in a Neural Network](https://www.youtube.com/watch?v=iuJgyiS7BKM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP06JifmqTB-"
      },
      "source": [
        "##[34. Batch Size in a Neural Network](https://www.youtube.com/watch?v=U4WB9p6ODjM&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlGcmepPrUZE"
      },
      "source": [
        "##[35. Fine-tuning a Neural Network](https://www.youtube.com/watch?v=5T-iXNNiwIs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3zR-SstIab"
      },
      "source": [
        "##[36. Batch Normalization (\"batch norm\")](https://www.youtube.com/watch?v=dXB-KQYkzNU&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=36)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcXKWvR4BX6z"
      },
      "source": [
        "#[Keras with TensorFlow Course - Python Deep Learning and Neural Networks for Beginners Tutorial](https://www.youtube.com/watch?v=qFJeN9V1ZsI&t=94s)\r\n",
        "- ⌨️ (00:00:00) Welcome to this course\r\n",
        "- ⌨️ (00:00:16) Keras Course Introduction\r\n",
        "- ⌨️ (00:00:50) Course Prerequisites\r\n",
        "- ⌨️ (00:01:33) DEEPLIZARD Deep Learning Path\r\n",
        "- ⌨️ (00:01:45) Course Resources\r\n",
        "- ⌨️ (00:02:30) About Keras\r\n",
        "- ⌨️ (00:06:41) Keras with TensorFlow - Data Processing for Neural Network Training\r\n",
        "- ⌨️ (00:18:39) Create an Artificial Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:24:36) Train an Artificial Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:30:07) Build a Validation Set With TensorFlow's Keras API\r\n",
        "- ⌨️ (00:39:28) Neural Network Predictions with TensorFlow's Keras API\r\n",
        "- ⌨️ (00:47:48) Create a Confusion Matrix for Neural Network Predictions\r\n",
        "- ⌨️ (00:52:29) Save and Load a Model with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:01:25) Image Preparation for CNNs with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:19:22) Build and Train a CNN with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:28:42) CNN Predictions with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:37:05) Build a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:48:19) Train a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:52:39) Predict with a Fine-Tuned Neural Network with TensorFlow's Keras API\r\n",
        "- ⌨️ (01:57:50) MobileNet Image Classification with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:11:18) Process Images for Fine-Tuned MobileNet with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:24:24) Fine-Tuning MobileNet on Custom Data Set with TensorFlow's Keras API\r\n",
        "- ⌨️ (02:38:59) Data Augmentation with TensorFlow' Keras API\r\n",
        "- ⌨️ (02:47:24) Collective Intelligence and the DEEPLIZARD HIVEMIND\r\n",
        "\r\n",
        "##[Keras](https://keras.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkrMXKB2FM9O"
      },
      "source": [
        "##Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqx_3BJuFMH9"
      },
      "source": [
        "import numpy as np\r\n",
        "from random import randint\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuBPczNLGCxl"
      },
      "source": [
        "###Example data:\r\n",
        "- An experiemental drug was tested on individuals from ages 13 to 100 in a clinical trial.\r\n",
        "- The trial has 2100 participants. Half were under 65 years old, half were 65 years older.\r\n",
        "- Around 95% of patients 65 or older experienced side effects.\r\n",
        "- Around 95% of patients under 65 experienced no side effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0MtYZNkFzky"
      },
      "source": [
        "train_labels = []\r\n",
        "train_samples = []\r\n",
        "\r\n",
        "for i in range(50):\r\n",
        "  # The ~5% of younger individuals who did experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  train_samples.append(random_younger)\r\n",
        "  train_labels.append(1)\r\n",
        "\r\n",
        "  # The ~5% of older individuals who did not experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  train_samples.append(random_older)\r\n",
        "  train_labels.append(0)\r\n",
        "\r\n",
        "for i in range(1000):\r\n",
        "  # The ~95% of younger individuals who did not experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  train_samples.append(random_younger)\r\n",
        "  train_labels.append(0)\r\n",
        "\r\n",
        "  # The ~95% of older individuals who did experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  train_samples.append(random_older)\r\n",
        "  train_labels.append(1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq8VcMQhKA3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b73d6ba-4551-49bb-a545-fdc5e878f083"
      },
      "source": [
        "train_labels = np.array(train_labels)\r\n",
        "train_samples = np.array(train_samples)\r\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)\r\n",
        "\r\n",
        "print(train_labels)\r\n",
        "print(train_samples)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 0 1]\n",
            "[97 56 84 ... 74 58 81]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO2MVDLb8RKE",
        "outputId": "ba290d13-2edb-465a-ed51-4a7423acc806"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\r\n",
        "print(scaler)\r\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))\r\n",
        "print(scaled_train_samples)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "[[0.96551724]\n",
            " [0.49425287]\n",
            " [0.81609195]\n",
            " ...\n",
            " [0.70114943]\n",
            " [0.51724138]\n",
            " [0.7816092 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V05dNMgk9OfF"
      },
      "source": [
        "##Create an Artificial Neural Network with TensorFlow's Keras API \r\n",
        "###Simple tf.keras Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcds_84B9WY8"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Activation, Dense\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "7_TG1fnB93LG",
        "outputId": "8cef5a1a-1930-480d-ea1a-2188ba94a8cb"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "print('Num GPUs Available: ', len(physical_devices))\r\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b42eb6479b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Num GPUs Available: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAy70bCb-OCc"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\r\n",
        "    Dense(units=32, activation='relu'),\r\n",
        "    Dense(units=2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-lqVj8E86AN",
        "outputId": "c142ecbe-8cff-41c6-853c-f5023e6eab8f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrW7MSDP_2DT"
      },
      "source": [
        "## Train an Artificial Neural Network with TensorFlow's Keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWDpFKyl-45J",
        "outputId": "c7bb1300-d5a7-4fb6-a358-09a6760b816d"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 0s - loss: 0.2330 - accuracy: 0.9524\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.2330 - accuracy: 0.9505\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.2328 - accuracy: 0.9514\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.2328 - accuracy: 0.9524\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.2327 - accuracy: 0.9524\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.2327 - accuracy: 0.9524\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.2325 - accuracy: 0.9524\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.2324 - accuracy: 0.9524\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.2323 - accuracy: 0.9524\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.2322 - accuracy: 0.9490\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.2321 - accuracy: 0.9524\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.2320 - accuracy: 0.9524\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.2320 - accuracy: 0.9524\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.2318 - accuracy: 0.9524\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.2319 - accuracy: 0.9524\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.2317 - accuracy: 0.9524\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2317 - accuracy: 0.9524\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2315 - accuracy: 0.9524\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2314 - accuracy: 0.9524\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2312 - accuracy: 0.9524\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2311 - accuracy: 0.9524\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2311 - accuracy: 0.9524\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2310 - accuracy: 0.9495\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2309 - accuracy: 0.9524\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2307 - accuracy: 0.9495\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2308 - accuracy: 0.9524\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2306 - accuracy: 0.9524\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2306 - accuracy: 0.9524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd33bb5c208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBj3KDGoB_0w"
      },
      "source": [
        "##Build a Validation Set With TensorFlow's Keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rli-mnu0CDpd",
        "outputId": "897c0fa1-32ba-4a01-a319-a4cd5dffb624"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 1s - loss: 0.2704 - accuracy: 0.9381 - val_loss: 0.2932 - val_accuracy: 0.9286\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.2688 - accuracy: 0.9365 - val_loss: 0.2912 - val_accuracy: 0.9286\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.2674 - accuracy: 0.9418 - val_loss: 0.2908 - val_accuracy: 0.9143\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.2659 - accuracy: 0.9434 - val_loss: 0.2896 - val_accuracy: 0.9143\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.2650 - accuracy: 0.9386 - val_loss: 0.2879 - val_accuracy: 0.9286\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.2639 - accuracy: 0.9407 - val_loss: 0.2864 - val_accuracy: 0.9286\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.2630 - accuracy: 0.9429 - val_loss: 0.2857 - val_accuracy: 0.9286\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.2620 - accuracy: 0.9413 - val_loss: 0.2844 - val_accuracy: 0.9286\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.2611 - accuracy: 0.9444 - val_loss: 0.2841 - val_accuracy: 0.9286\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.2605 - accuracy: 0.9439 - val_loss: 0.2833 - val_accuracy: 0.9286\n",
            "Epoch 11/30\n",
            "189/189 - 0s - loss: 0.2598 - accuracy: 0.9439 - val_loss: 0.2829 - val_accuracy: 0.9143\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.2591 - accuracy: 0.9439 - val_loss: 0.2817 - val_accuracy: 0.9286\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.2583 - accuracy: 0.9439 - val_loss: 0.2808 - val_accuracy: 0.9286\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.2580 - accuracy: 0.9429 - val_loss: 0.2805 - val_accuracy: 0.9286\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.2572 - accuracy: 0.9439 - val_loss: 0.2791 - val_accuracy: 0.9286\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.2566 - accuracy: 0.9439 - val_loss: 0.2792 - val_accuracy: 0.9286\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.2562 - accuracy: 0.9439 - val_loss: 0.2782 - val_accuracy: 0.9286\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.2557 - accuracy: 0.9460 - val_loss: 0.2783 - val_accuracy: 0.9286\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2552 - accuracy: 0.9429 - val_loss: 0.2766 - val_accuracy: 0.9286\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2547 - accuracy: 0.9439 - val_loss: 0.2762 - val_accuracy: 0.9286\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2544 - accuracy: 0.9439 - val_loss: 0.2756 - val_accuracy: 0.9286\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2539 - accuracy: 0.9434 - val_loss: 0.2751 - val_accuracy: 0.9286\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2534 - accuracy: 0.9439 - val_loss: 0.2753 - val_accuracy: 0.9286\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2530 - accuracy: 0.9439 - val_loss: 0.2742 - val_accuracy: 0.9286\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2526 - accuracy: 0.9439 - val_loss: 0.2743 - val_accuracy: 0.9286\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2523 - accuracy: 0.9439 - val_loss: 0.2741 - val_accuracy: 0.9286\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2519 - accuracy: 0.9439 - val_loss: 0.2731 - val_accuracy: 0.9286\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2516 - accuracy: 0.9439 - val_loss: 0.2730 - val_accuracy: 0.9286\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2512 - accuracy: 0.9439 - val_loss: 0.2723 - val_accuracy: 0.9286\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2509 - accuracy: 0.9439 - val_loss: 0.2715 - val_accuracy: 0.9286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd33a126668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9I43_ESGcdP"
      },
      "source": [
        "##Neural Network Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZwJ8g27GhOY"
      },
      "source": [
        "test_labels = []\r\n",
        "test_samples = []\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  # The ~5% of younger individuals who did experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  test_samples.append(random_younger)\r\n",
        "  test_labels.append(1)\r\n",
        "\r\n",
        "  # The ~5% of older individuals who did not experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  test_samples.append(random_older)\r\n",
        "  test_labels.append(0)\r\n",
        "\r\n",
        "for i in range(200):\r\n",
        "  # The ~95% of younger individuals who did not experience side effects\r\n",
        "  random_younger = randint(13, 64)\r\n",
        "  test_samples.append(random_younger)\r\n",
        "  test_labels.append(0)\r\n",
        "\r\n",
        "  # The ~95% of older individuals who did experience side effects\r\n",
        "  random_older = randint(65, 100)\r\n",
        "  test_samples.append(random_older)\r\n",
        "  test_labels.append(1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU1SHdeaHiAW",
        "outputId": "08ee9ced-833a-4d90-96c8-6144e6ee4f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_labels = np.array(test_labels)\r\n",
        "test_samples = np.array(test_samples)\r\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)\r\n",
        "\r\n",
        "print(test_labels)\r\n",
        "print(test_samples)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 0 1 0 0 1 0 1]\n",
            "[ 18  84  50  60  43  26  33  48  55  62  66  39  51  36  35  70  25  57\n",
            "  58  25  87  78  16  17  67  31  86  90  82  31  26  84  92  89  85  86\n",
            "  54  19  23  15  33  72  31  24  87  76  74  94  92  50  84  26  68  32\n",
            "  63  96  79  69  71  92  78  45  22  18  59  50  16  86  93  79  82  47\n",
            "  92  71  32  75  73  53  75  49  20  54  58  98  93  83  79  70  19  78\n",
            "  59  26  59  71  28  24  57  97  41  79  65  82  38  96  68  62  27  15\n",
            "  98  46  74  38  76  71  82  39  93  56  63  80  99  84  72  40  66  43\n",
            " 100  47  36  69  25  96  21  82  25  86  61  25  90  94  58  78  32 100\n",
            "  81  91  96  84  95  19  48  55  78  96  84  99  66  83  49  98  62  74\n",
            "  43  94  85  20  63  90  88  73  54  73  38  87  15  28  90  90  44  90\n",
            "  97 100  37  95  90  96  85  55  88  90  38  53  36  77  82  54  78  82\n",
            "  34  17  83  79  70  83  61  32  32  56  36  43  36  54  54  49  81  39\n",
            "  33  22  31  13  16  70  24  25  45  67  48  45  34  75  57  74  56  33\n",
            "  18  30  43  93  16  63  86  33  78  13  94  72  83  28  49  23  26  99\n",
            " 100  55  70  78  31  70  29  40  67  32  17  69  57  74  74  86  85  14\n",
            "  44  87  43  71  61  45  81  73  49  39  90  85  91  72  74 100  74  25\n",
            "  80  94  33  42  73  70  38  53  51  20  81 100  30  87  36  71  67  39\n",
            "  22  94  67  96  56  24  65  32  90  71  92  58  63  95  31  58  31  94\n",
            "  33  82  87  15  58  21  91  23  36  56  82  63  83  54  75  71  94  60\n",
            "  81  19  89  88  18  32  69  72  88  81  93  54  67  40  82  40  83  77\n",
            "  33  53  28  21  43  22  32 100  90  69  92  69  97  24  58  30  93  25\n",
            "  27  82  81  67  51  53  32  71  86  66  46  44  56  49  93  66  89  88\n",
            "  43  76  38  78  45  69  84  35  77  95  89  98  99  52  69  96  15  19\n",
            "  63  59  17  71  27  68]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vGN3pjYHz5N",
        "outputId": "aef38aab-aa44-4f77-f688-68a1852af285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))\r\n",
        "print(scaled_test_samples)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.05747126]\n",
            " [0.81609195]\n",
            " [0.42528736]\n",
            " [0.54022989]\n",
            " [0.34482759]\n",
            " [0.14942529]\n",
            " [0.22988506]\n",
            " [0.40229885]\n",
            " [0.48275862]\n",
            " [0.56321839]\n",
            " [0.6091954 ]\n",
            " [0.29885057]\n",
            " [0.43678161]\n",
            " [0.26436782]\n",
            " [0.25287356]\n",
            " [0.65517241]\n",
            " [0.13793103]\n",
            " [0.50574713]\n",
            " [0.51724138]\n",
            " [0.13793103]\n",
            " [0.85057471]\n",
            " [0.74712644]\n",
            " [0.03448276]\n",
            " [0.04597701]\n",
            " [0.62068966]\n",
            " [0.20689655]\n",
            " [0.83908046]\n",
            " [0.88505747]\n",
            " [0.79310345]\n",
            " [0.20689655]\n",
            " [0.14942529]\n",
            " [0.81609195]\n",
            " [0.90804598]\n",
            " [0.87356322]\n",
            " [0.82758621]\n",
            " [0.83908046]\n",
            " [0.47126437]\n",
            " [0.06896552]\n",
            " [0.11494253]\n",
            " [0.02298851]\n",
            " [0.22988506]\n",
            " [0.67816092]\n",
            " [0.20689655]\n",
            " [0.12643678]\n",
            " [0.85057471]\n",
            " [0.72413793]\n",
            " [0.70114943]\n",
            " [0.93103448]\n",
            " [0.90804598]\n",
            " [0.42528736]\n",
            " [0.81609195]\n",
            " [0.14942529]\n",
            " [0.63218391]\n",
            " [0.2183908 ]\n",
            " [0.57471264]\n",
            " [0.95402299]\n",
            " [0.75862069]\n",
            " [0.64367816]\n",
            " [0.66666667]\n",
            " [0.90804598]\n",
            " [0.74712644]\n",
            " [0.36781609]\n",
            " [0.10344828]\n",
            " [0.05747126]\n",
            " [0.52873563]\n",
            " [0.42528736]\n",
            " [0.03448276]\n",
            " [0.83908046]\n",
            " [0.91954023]\n",
            " [0.75862069]\n",
            " [0.79310345]\n",
            " [0.3908046 ]\n",
            " [0.90804598]\n",
            " [0.66666667]\n",
            " [0.2183908 ]\n",
            " [0.71264368]\n",
            " [0.68965517]\n",
            " [0.45977011]\n",
            " [0.71264368]\n",
            " [0.4137931 ]\n",
            " [0.08045977]\n",
            " [0.47126437]\n",
            " [0.51724138]\n",
            " [0.97701149]\n",
            " [0.91954023]\n",
            " [0.8045977 ]\n",
            " [0.75862069]\n",
            " [0.65517241]\n",
            " [0.06896552]\n",
            " [0.74712644]\n",
            " [0.52873563]\n",
            " [0.14942529]\n",
            " [0.52873563]\n",
            " [0.66666667]\n",
            " [0.17241379]\n",
            " [0.12643678]\n",
            " [0.50574713]\n",
            " [0.96551724]\n",
            " [0.32183908]\n",
            " [0.75862069]\n",
            " [0.59770115]\n",
            " [0.79310345]\n",
            " [0.28735632]\n",
            " [0.95402299]\n",
            " [0.63218391]\n",
            " [0.56321839]\n",
            " [0.16091954]\n",
            " [0.02298851]\n",
            " [0.97701149]\n",
            " [0.37931034]\n",
            " [0.70114943]\n",
            " [0.28735632]\n",
            " [0.72413793]\n",
            " [0.66666667]\n",
            " [0.79310345]\n",
            " [0.29885057]\n",
            " [0.91954023]\n",
            " [0.49425287]\n",
            " [0.57471264]\n",
            " [0.77011494]\n",
            " [0.98850575]\n",
            " [0.81609195]\n",
            " [0.67816092]\n",
            " [0.31034483]\n",
            " [0.6091954 ]\n",
            " [0.34482759]\n",
            " [1.        ]\n",
            " [0.3908046 ]\n",
            " [0.26436782]\n",
            " [0.64367816]\n",
            " [0.13793103]\n",
            " [0.95402299]\n",
            " [0.09195402]\n",
            " [0.79310345]\n",
            " [0.13793103]\n",
            " [0.83908046]\n",
            " [0.55172414]\n",
            " [0.13793103]\n",
            " [0.88505747]\n",
            " [0.93103448]\n",
            " [0.51724138]\n",
            " [0.74712644]\n",
            " [0.2183908 ]\n",
            " [1.        ]\n",
            " [0.7816092 ]\n",
            " [0.89655172]\n",
            " [0.95402299]\n",
            " [0.81609195]\n",
            " [0.94252874]\n",
            " [0.06896552]\n",
            " [0.40229885]\n",
            " [0.48275862]\n",
            " [0.74712644]\n",
            " [0.95402299]\n",
            " [0.81609195]\n",
            " [0.98850575]\n",
            " [0.6091954 ]\n",
            " [0.8045977 ]\n",
            " [0.4137931 ]\n",
            " [0.97701149]\n",
            " [0.56321839]\n",
            " [0.70114943]\n",
            " [0.34482759]\n",
            " [0.93103448]\n",
            " [0.82758621]\n",
            " [0.08045977]\n",
            " [0.57471264]\n",
            " [0.88505747]\n",
            " [0.86206897]\n",
            " [0.68965517]\n",
            " [0.47126437]\n",
            " [0.68965517]\n",
            " [0.28735632]\n",
            " [0.85057471]\n",
            " [0.02298851]\n",
            " [0.17241379]\n",
            " [0.88505747]\n",
            " [0.88505747]\n",
            " [0.35632184]\n",
            " [0.88505747]\n",
            " [0.96551724]\n",
            " [1.        ]\n",
            " [0.27586207]\n",
            " [0.94252874]\n",
            " [0.88505747]\n",
            " [0.95402299]\n",
            " [0.82758621]\n",
            " [0.48275862]\n",
            " [0.86206897]\n",
            " [0.88505747]\n",
            " [0.28735632]\n",
            " [0.45977011]\n",
            " [0.26436782]\n",
            " [0.73563218]\n",
            " [0.79310345]\n",
            " [0.47126437]\n",
            " [0.74712644]\n",
            " [0.79310345]\n",
            " [0.24137931]\n",
            " [0.04597701]\n",
            " [0.8045977 ]\n",
            " [0.75862069]\n",
            " [0.65517241]\n",
            " [0.8045977 ]\n",
            " [0.55172414]\n",
            " [0.2183908 ]\n",
            " [0.2183908 ]\n",
            " [0.49425287]\n",
            " [0.26436782]\n",
            " [0.34482759]\n",
            " [0.26436782]\n",
            " [0.47126437]\n",
            " [0.47126437]\n",
            " [0.4137931 ]\n",
            " [0.7816092 ]\n",
            " [0.29885057]\n",
            " [0.22988506]\n",
            " [0.10344828]\n",
            " [0.20689655]\n",
            " [0.        ]\n",
            " [0.03448276]\n",
            " [0.65517241]\n",
            " [0.12643678]\n",
            " [0.13793103]\n",
            " [0.36781609]\n",
            " [0.62068966]\n",
            " [0.40229885]\n",
            " [0.36781609]\n",
            " [0.24137931]\n",
            " [0.71264368]\n",
            " [0.50574713]\n",
            " [0.70114943]\n",
            " [0.49425287]\n",
            " [0.22988506]\n",
            " [0.05747126]\n",
            " [0.1954023 ]\n",
            " [0.34482759]\n",
            " [0.91954023]\n",
            " [0.03448276]\n",
            " [0.57471264]\n",
            " [0.83908046]\n",
            " [0.22988506]\n",
            " [0.74712644]\n",
            " [0.        ]\n",
            " [0.93103448]\n",
            " [0.67816092]\n",
            " [0.8045977 ]\n",
            " [0.17241379]\n",
            " [0.4137931 ]\n",
            " [0.11494253]\n",
            " [0.14942529]\n",
            " [0.98850575]\n",
            " [1.        ]\n",
            " [0.48275862]\n",
            " [0.65517241]\n",
            " [0.74712644]\n",
            " [0.20689655]\n",
            " [0.65517241]\n",
            " [0.18390805]\n",
            " [0.31034483]\n",
            " [0.62068966]\n",
            " [0.2183908 ]\n",
            " [0.04597701]\n",
            " [0.64367816]\n",
            " [0.50574713]\n",
            " [0.70114943]\n",
            " [0.70114943]\n",
            " [0.83908046]\n",
            " [0.82758621]\n",
            " [0.01149425]\n",
            " [0.35632184]\n",
            " [0.85057471]\n",
            " [0.34482759]\n",
            " [0.66666667]\n",
            " [0.55172414]\n",
            " [0.36781609]\n",
            " [0.7816092 ]\n",
            " [0.68965517]\n",
            " [0.4137931 ]\n",
            " [0.29885057]\n",
            " [0.88505747]\n",
            " [0.82758621]\n",
            " [0.89655172]\n",
            " [0.67816092]\n",
            " [0.70114943]\n",
            " [1.        ]\n",
            " [0.70114943]\n",
            " [0.13793103]\n",
            " [0.77011494]\n",
            " [0.93103448]\n",
            " [0.22988506]\n",
            " [0.33333333]\n",
            " [0.68965517]\n",
            " [0.65517241]\n",
            " [0.28735632]\n",
            " [0.45977011]\n",
            " [0.43678161]\n",
            " [0.08045977]\n",
            " [0.7816092 ]\n",
            " [1.        ]\n",
            " [0.1954023 ]\n",
            " [0.85057471]\n",
            " [0.26436782]\n",
            " [0.66666667]\n",
            " [0.62068966]\n",
            " [0.29885057]\n",
            " [0.10344828]\n",
            " [0.93103448]\n",
            " [0.62068966]\n",
            " [0.95402299]\n",
            " [0.49425287]\n",
            " [0.12643678]\n",
            " [0.59770115]\n",
            " [0.2183908 ]\n",
            " [0.88505747]\n",
            " [0.66666667]\n",
            " [0.90804598]\n",
            " [0.51724138]\n",
            " [0.57471264]\n",
            " [0.94252874]\n",
            " [0.20689655]\n",
            " [0.51724138]\n",
            " [0.20689655]\n",
            " [0.93103448]\n",
            " [0.22988506]\n",
            " [0.79310345]\n",
            " [0.85057471]\n",
            " [0.02298851]\n",
            " [0.51724138]\n",
            " [0.09195402]\n",
            " [0.89655172]\n",
            " [0.11494253]\n",
            " [0.26436782]\n",
            " [0.49425287]\n",
            " [0.79310345]\n",
            " [0.57471264]\n",
            " [0.8045977 ]\n",
            " [0.47126437]\n",
            " [0.71264368]\n",
            " [0.66666667]\n",
            " [0.93103448]\n",
            " [0.54022989]\n",
            " [0.7816092 ]\n",
            " [0.06896552]\n",
            " [0.87356322]\n",
            " [0.86206897]\n",
            " [0.05747126]\n",
            " [0.2183908 ]\n",
            " [0.64367816]\n",
            " [0.67816092]\n",
            " [0.86206897]\n",
            " [0.7816092 ]\n",
            " [0.91954023]\n",
            " [0.47126437]\n",
            " [0.62068966]\n",
            " [0.31034483]\n",
            " [0.79310345]\n",
            " [0.31034483]\n",
            " [0.8045977 ]\n",
            " [0.73563218]\n",
            " [0.22988506]\n",
            " [0.45977011]\n",
            " [0.17241379]\n",
            " [0.09195402]\n",
            " [0.34482759]\n",
            " [0.10344828]\n",
            " [0.2183908 ]\n",
            " [1.        ]\n",
            " [0.88505747]\n",
            " [0.64367816]\n",
            " [0.90804598]\n",
            " [0.64367816]\n",
            " [0.96551724]\n",
            " [0.12643678]\n",
            " [0.51724138]\n",
            " [0.1954023 ]\n",
            " [0.91954023]\n",
            " [0.13793103]\n",
            " [0.16091954]\n",
            " [0.79310345]\n",
            " [0.7816092 ]\n",
            " [0.62068966]\n",
            " [0.43678161]\n",
            " [0.45977011]\n",
            " [0.2183908 ]\n",
            " [0.66666667]\n",
            " [0.83908046]\n",
            " [0.6091954 ]\n",
            " [0.37931034]\n",
            " [0.35632184]\n",
            " [0.49425287]\n",
            " [0.4137931 ]\n",
            " [0.91954023]\n",
            " [0.6091954 ]\n",
            " [0.87356322]\n",
            " [0.86206897]\n",
            " [0.34482759]\n",
            " [0.72413793]\n",
            " [0.28735632]\n",
            " [0.74712644]\n",
            " [0.36781609]\n",
            " [0.64367816]\n",
            " [0.81609195]\n",
            " [0.25287356]\n",
            " [0.73563218]\n",
            " [0.94252874]\n",
            " [0.87356322]\n",
            " [0.97701149]\n",
            " [0.98850575]\n",
            " [0.44827586]\n",
            " [0.64367816]\n",
            " [0.95402299]\n",
            " [0.02298851]\n",
            " [0.06896552]\n",
            " [0.57471264]\n",
            " [0.52873563]\n",
            " [0.04597701]\n",
            " [0.66666667]\n",
            " [0.16091954]\n",
            " [0.63218391]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYLwiLfjIRVZ",
        "outputId": "56181a17-31b9-49f7-f779-b1283f5b29a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)\r\n",
        "print(predictions.shape)\r\n",
        "print(predictions)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 2)\n",
            "[[0.97432363 0.02567634]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.9166857  0.08331436]\n",
            " [0.6631673  0.3368327 ]\n",
            " [0.95384926 0.04615078]\n",
            " [0.9725893  0.02741066]\n",
            " [0.9699461  0.03005392]\n",
            " [0.93161637 0.06838365]\n",
            " [0.8273128  0.17268714]\n",
            " [0.57974726 0.42025274]\n",
            " [0.40379623 0.59620374]\n",
            " [0.96309984 0.0369002 ]\n",
            " [0.9061441  0.09385588]\n",
            " [0.96695584 0.03304411]\n",
            " [0.9681525  0.03184744]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.77047527 0.22952472]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.04253287 0.95746714]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.97474027 0.02525972]\n",
            " [0.97453284 0.0254672 ]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.97114843 0.02885155]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.06621147 0.93378854]\n",
            " [0.97114843 0.02885155]\n",
            " [0.9725893  0.02741066]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.0355348  0.9644652 ]\n",
            " [0.05083647 0.94916356]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.97411287 0.02588714]\n",
            " [0.9732527  0.02674733]\n",
            " [0.97494614 0.0250539 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.18895958 0.8110404 ]\n",
            " [0.97114843 0.02885155]\n",
            " [0.97303337 0.02696669]\n",
            " [0.04253287 0.95746714]\n",
            " [0.1105383  0.88946176]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.9166857  0.08331436]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.9725893  0.02741066]\n",
            " [0.32182956 0.6781705 ]\n",
            " [0.9705532  0.02944679]\n",
            " [0.5359092  0.46409082]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.08581607 0.91418386]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.21773186 0.78226817]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.9460773  0.0539227 ]\n",
            " [0.97347033 0.02652972]\n",
            " [0.97432363 0.02567634]\n",
            " [0.7016763  0.29832372]\n",
            " [0.9166857  0.08331436]\n",
            " [0.97474027 0.02525972]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.02471895 0.97528106]\n",
            " [0.08581607 0.91418386]\n",
            " [0.06621147 0.93378854]\n",
            " [0.936797   0.06320293]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.21773186 0.78226817]\n",
            " [0.9705532  0.02944679]\n",
            " [0.1221136  0.87788635]\n",
            " [0.16319615 0.83680385]\n",
            " [0.8724064  0.12759356]\n",
            " [0.1221136  0.87788635]\n",
            " [0.92516804 0.07483191]\n",
            " [0.9739004  0.02609962]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.01563055 0.9843694 ]\n",
            " [0.02471895 0.97528106]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.08581607 0.91418386]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.97411287 0.02588714]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.7016763  0.29832372]\n",
            " [0.9725893  0.02741066]\n",
            " [0.7016763  0.29832372]\n",
            " [0.21773186 0.78226817]\n",
            " [0.9721382  0.02786173]\n",
            " [0.97303337 0.02696669]\n",
            " [0.77047527 0.22952472]\n",
            " [0.01713667 0.98286337]\n",
            " [0.9590841  0.04091592]\n",
            " [0.08581607 0.91418386]\n",
            " [0.44724214 0.55275786]\n",
            " [0.06621147 0.93378854]\n",
            " [0.964431   0.03556902]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.32182956 0.6781705 ]\n",
            " [0.57974726 0.42025277]\n",
            " [0.9723647  0.0276353 ]\n",
            " [0.97494614 0.0250539 ]\n",
            " [0.01563055 0.9843694 ]\n",
            " [0.9416098  0.05839011]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.964431   0.03556902]\n",
            " [0.1105383  0.88946176]\n",
            " [0.21773186 0.78226817]\n",
            " [0.06621147 0.93378854]\n",
            " [0.96309984 0.0369002 ]\n",
            " [0.02471895 0.97528106]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.5359092  0.46409082]\n",
            " [0.07875755 0.9212424 ]\n",
            " [0.0142549  0.9857451 ]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.18895958 0.8110404 ]\n",
            " [0.9614836  0.03851638]\n",
            " [0.40379623 0.59620374]\n",
            " [0.95384926 0.04615078]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.936797   0.06320293]\n",
            " [0.96695584 0.03304411]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.97368616 0.02631382]\n",
            " [0.06621147 0.93378854]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.6223626  0.37763742]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.9705532  0.02944679]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.02965248 0.9703475 ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.02058883 0.9794112 ]\n",
            " [0.97411287 0.02588714]\n",
            " [0.93161637 0.06838365]\n",
            " [0.8273128  0.17268714]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.0142549  0.9857451 ]\n",
            " [0.40379623 0.59620374]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.92516804 0.07483191]\n",
            " [0.01563055 0.9843694 ]\n",
            " [0.57974726 0.42025277]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.95384926 0.04615078]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.05083647 0.94916356]\n",
            " [0.9739004  0.02609962]\n",
            " [0.5359092  0.46409082]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.03888305 0.96111697]\n",
            " [0.16319615 0.83680385]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.16319615 0.83680385]\n",
            " [0.964431   0.03556902]\n",
            " [0.04253287 0.95746714]\n",
            " [0.97494614 0.0250539 ]\n",
            " [0.9721382  0.02786173]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.950221   0.049779  ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.01713667 0.98286337]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.9657159  0.03428416]\n",
            " [0.02058883 0.9794112 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.05083647 0.94916356]\n",
            " [0.8273128  0.17268714]\n",
            " [0.03888305 0.96111697]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.964431   0.03556902]\n",
            " [0.8724064  0.12759356]\n",
            " [0.96695584 0.03304411]\n",
            " [0.10167248 0.8983276 ]\n",
            " [0.06621147 0.93378854]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.06621147 0.93378854]\n",
            " [0.96930724 0.03069272]\n",
            " [0.97453284 0.0254672 ]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.08581607 0.91418386]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.6223626  0.37763742]\n",
            " [0.9705532  0.02944679]\n",
            " [0.9705532  0.02944679]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.96695584 0.03304411]\n",
            " [0.95384926 0.04615078]\n",
            " [0.96695584 0.03304411]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.92516804 0.07483191]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.96309984 0.0369002 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.97347033 0.02652972]\n",
            " [0.97114843 0.02885155]\n",
            " [0.9753528  0.02464713]\n",
            " [0.97474027 0.02525972]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.97303337 0.02696669]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.9460773  0.0539227 ]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.93161637 0.06838365]\n",
            " [0.9460773  0.0539227 ]\n",
            " [0.96930724 0.03069272]\n",
            " [0.1221136  0.87788635]\n",
            " [0.77047527 0.22952472]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.97432363 0.02567634]\n",
            " [0.97168005 0.02832001]\n",
            " [0.95384926 0.04615078]\n",
            " [0.02471895 0.97528106]\n",
            " [0.97474027 0.02525972]\n",
            " [0.5359092  0.46409082]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.9753528  0.02464713]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.18895958 0.8110404 ]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.9721382  0.02786173]\n",
            " [0.92516804 0.07483191]\n",
            " [0.9732527  0.02674733]\n",
            " [0.9725893  0.02741066]\n",
            " [0.0142549  0.9857451 ]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.8273128  0.17268714]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.97114843 0.02885155]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.97191006 0.02808996]\n",
            " [0.9614836  0.03851638]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.9705532  0.02944679]\n",
            " [0.97453284 0.0254672 ]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.77047527 0.22952472]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.05083647 0.94916356]\n",
            " [0.97515035 0.02484971]\n",
            " [0.950221   0.049779  ]\n",
            " [0.04253287 0.95746714]\n",
            " [0.95384926 0.04615078]\n",
            " [0.21773186 0.78226817]\n",
            " [0.6223626  0.37763742]\n",
            " [0.9460773  0.0539227 ]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.16319615 0.83680385]\n",
            " [0.92516804 0.07483191]\n",
            " [0.96309984 0.0369002 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.05083647 0.94916356]\n",
            " [0.02965248 0.9703475 ]\n",
            " [0.18895958 0.8110404 ]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.14055026 0.8594498 ]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.07875755 0.9212424 ]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.95654184 0.04345817]\n",
            " [0.16319615 0.83680385]\n",
            " [0.24953742 0.7504626 ]\n",
            " [0.964431   0.03556902]\n",
            " [0.8724064  0.12759356]\n",
            " [0.9061441  0.09385588]\n",
            " [0.9739004  0.02609962]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.97168005 0.02832001]\n",
            " [0.04253287 0.95746714]\n",
            " [0.96695584 0.03304411]\n",
            " [0.21773186 0.78226817]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.96309984 0.0369002 ]\n",
            " [0.97347033 0.02652972]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.97303337 0.02696669]\n",
            " [0.44724214 0.55275786]\n",
            " [0.9705532  0.02944679]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.21773186 0.78226817]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.5359092  0.46409082]\n",
            " [0.02058883 0.9794112 ]\n",
            " [0.97114843 0.02885155]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.97114843 0.02885155]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.06621147 0.93378854]\n",
            " [0.04253287 0.95746714]\n",
            " [0.97494614 0.0250539 ]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.97368616 0.02631382]\n",
            " [0.02965248 0.9703475 ]\n",
            " [0.9732527  0.02674733]\n",
            " [0.96695584 0.03304411]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.06621147 0.93378854]\n",
            " [0.5359092  0.46409082]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.1221136  0.87788635]\n",
            " [0.21773186 0.78226817]\n",
            " [0.02256175 0.9774383 ]\n",
            " [0.6631673  0.3368327 ]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.97411287 0.02588714]\n",
            " [0.0355348  0.9644652 ]\n",
            " [0.03888305 0.96111697]\n",
            " [0.97432363 0.02567634]\n",
            " [0.9705532  0.02944679]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.18895958 0.8110404 ]\n",
            " [0.03888305 0.96111697]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.02471895 0.97528106]\n",
            " [0.8512645  0.1487355 ]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.9614836  0.03851638]\n",
            " [0.06621147 0.93378854]\n",
            " [0.9614836  0.03851638]\n",
            " [0.0606585  0.9393415 ]\n",
            " [0.10167248 0.8983276 ]\n",
            " [0.9699461  0.03005392]\n",
            " [0.8724064  0.12759356]\n",
            " [0.9721382  0.02786173]\n",
            " [0.97368616 0.02631382]\n",
            " [0.95384926 0.04615078]\n",
            " [0.97347033 0.02652972]\n",
            " [0.9705532  0.02944679]\n",
            " [0.01299872 0.9870013 ]\n",
            " [0.03246514 0.9675348 ]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.0270767  0.9729233 ]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.01713667 0.98286337]\n",
            " [0.97303337 0.02696669]\n",
            " [0.7375252  0.2624748 ]\n",
            " [0.97168005 0.02832001]\n",
            " [0.02471895 0.97528106]\n",
            " [0.9728122  0.0271878 ]\n",
            " [0.9723647  0.0276353 ]\n",
            " [0.06621147 0.93378854]\n",
            " [0.07223372 0.9277663 ]\n",
            " [0.3618084  0.6381916 ]\n",
            " [0.9061441  0.09385588]\n",
            " [0.8724064  0.12759356]\n",
            " [0.9705532  0.02944679]\n",
            " [0.21773186 0.78226817]\n",
            " [0.04650871 0.9534912 ]\n",
            " [0.40379623 0.59620374]\n",
            " [0.9416098  0.05839011]\n",
            " [0.950221   0.049779  ]\n",
            " [0.80040854 0.1995915 ]\n",
            " [0.92516804 0.07483191]\n",
            " [0.02471895 0.97528106]\n",
            " [0.40379623 0.59620374]\n",
            " [0.0355348  0.9644652 ]\n",
            " [0.03888305 0.96111697]\n",
            " [0.95384926 0.04615078]\n",
            " [0.1105383  0.88946176]\n",
            " [0.964431   0.03556902]\n",
            " [0.09344301 0.906557  ]\n",
            " [0.9460773  0.0539227 ]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.0555435  0.9444565 ]\n",
            " [0.9681525  0.03184744]\n",
            " [0.10167248 0.8983276 ]\n",
            " [0.02058883 0.9794112 ]\n",
            " [0.0355348  0.9644652 ]\n",
            " [0.01563055 0.9843694 ]\n",
            " [0.0142549  0.9857451 ]\n",
            " [0.89092827 0.10907176]\n",
            " [0.28430048 0.7156995 ]\n",
            " [0.01878513 0.9812149 ]\n",
            " [0.97494614 0.0250539 ]\n",
            " [0.97411287 0.02588714]\n",
            " [0.5359092  0.46409082]\n",
            " [0.7016763  0.29832372]\n",
            " [0.97453284 0.0254672 ]\n",
            " [0.21773186 0.78226817]\n",
            " [0.9723647  0.0276353 ]\n",
            " [0.32182956 0.6781705 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T76sfEIiJHqV",
        "outputId": "b2475180-4950-4a3c-9af9-8ddef8079d7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=1)\r\n",
        "print(rounded_predictions.shape)\r\n",
        "print(rounded_predictions)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420,)\n",
            "[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etB_2F87AMXI"
      },
      "source": [
        "#[Practical Machine Learning Tutorial with Python -  sentdex](https://www.youtube.com/watch?v=OGxgnH8y2NM&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM33OqbLQx0d"
      },
      "source": [
        "##Install Packages\r\n",
        "- ```pip install sklean```\r\n",
        "- ```pip install quandl```\r\n",
        "- ```pip isntall pandas```\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnN9sjshQr3e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPfaXhW-QBE"
      },
      "source": [
        "#[Deep Learning - 3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic2lNYazNi6f"
      },
      "source": [
        "#[Practical Deep Learning for Coders - Full Course from fast.ai and Jeremy Howard](https://www.youtube.com/watch?v=0oyCUWLL_fU&list=RDCMUC8butISFwT-Wl7EV0hUK0BQ&start_radio=1&t=55)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vjCzKlNDF0K"
      },
      "source": [
        "#[Python for Data Science](https://www.youtube.com/watch?v=LHBE6Q9XlzI&t=40900s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2iOeIVsDTdR"
      },
      "source": [
        "#[Learn Data Science Tutorial - Full Course for Beginners](https://www.youtube.com/watch?v=ua-CiDNNj30)"
      ]
    }
  ]
}